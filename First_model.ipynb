{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lead Protein ID</th>\n",
       "      <th>Compartment Prediction</th>\n",
       "      <th>Prediction Confidence</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Sequence Lengh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q9Y619</td>\n",
       "      <td>Mitochondrion</td>\n",
       "      <td>Medium</td>\n",
       "      <td>MKSNPAIQAAIDLTAGAAGGTACVLTGQPFDTMKVKMQTFPDLYRG...</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q6Q0C0</td>\n",
       "      <td>Plasma membrane</td>\n",
       "      <td>Medium</td>\n",
       "      <td>MSSGKSARYNRFSGGPSNLPTPDVTTGTRMETTFGPAFSAVTTITK...</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O95834</td>\n",
       "      <td>Large Protein Complex</td>\n",
       "      <td>Medium</td>\n",
       "      <td>MSSFGAGKTKEVIFSVEDGSVKMFLRGRPVPMMIPDELAPTYSLDT...</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q9P0I2</td>\n",
       "      <td>ER</td>\n",
       "      <td>Medium</td>\n",
       "      <td>MAGPELLLDSNIRLWVVLPIVIITFFVGMIRHYVSILLQSDKKLTQ...</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q86UD0</td>\n",
       "      <td>Large Protein Complex</td>\n",
       "      <td>Low</td>\n",
       "      <td>MAGAAMAERGRVPPPAPAPSTEGLPRAFLQSLRTLFDILDDRRRGC...</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Lead Protein ID Compartment Prediction Prediction Confidence  \\\n",
       "0          Q9Y619          Mitochondrion                Medium   \n",
       "1          Q6Q0C0        Plasma membrane                Medium   \n",
       "2          O95834  Large Protein Complex                Medium   \n",
       "3          Q9P0I2                     ER                Medium   \n",
       "4          Q86UD0  Large Protein Complex                   Low   \n",
       "\n",
       "                                            Sequence  Sequence Lengh  \n",
       "0  MKSNPAIQAAIDLTAGAAGGTACVLTGQPFDTMKVKMQTFPDLYRG...             301  \n",
       "1  MSSGKSARYNRFSGGPSNLPTPDVTTGTRMETTFGPAFSAVTTITK...             670  \n",
       "2  MSSFGAGKTKEVIFSVEDGSVKMFLRGRPVPMMIPDELAPTYSLDT...             649  \n",
       "3  MAGPELLLDSNIRLWVVLPIVIITFFVGMIRHYVSILLQSDKKLTQ...             261  \n",
       "4  MAGAAMAERGRVPPPAPAPSTEGLPRAFLQSLRTLFDILDDRRRGC...             394  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/strat_train.csv\", sep=\"\\t\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3871, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lead Protein ID</th>\n",
       "      <th>Compartment Prediction</th>\n",
       "      <th>Prediction Confidence</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Sequence Lengh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P98173</td>\n",
       "      <td>Golgi</td>\n",
       "      <td>Medium</td>\n",
       "      <td>MRLAGPLRIVVLVVSVGVTWIVVSILLGGPGSGFPRIQQLFTSPES...</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P08195</td>\n",
       "      <td>Plasma membrane</td>\n",
       "      <td>Very High</td>\n",
       "      <td>MELQPPEASIAVVSIPRQLPGSHSEAGVQGLSAGDDSELGSHCVAQ...</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O43663</td>\n",
       "      <td>Large Protein Complex</td>\n",
       "      <td>High</td>\n",
       "      <td>MRRSEVLAEESIVCLQKALNHLREIWELIGIPEDQRLQRTEVVKKH...</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P51649</td>\n",
       "      <td>Mitochondrion</td>\n",
       "      <td>Medium</td>\n",
       "      <td>MATCIWLRSCGARRLGSTFPGCRLRPRAGGLVPASGPAPGPAQLRC...</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q68EM7</td>\n",
       "      <td>Large Protein Complex</td>\n",
       "      <td>Very High</td>\n",
       "      <td>MKKQFNRMKQLANQTVGRAEKTEVLSEDLLQIERRLDTVRSICHHS...</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Lead Protein ID Compartment Prediction Prediction Confidence  \\\n",
       "0          P98173                  Golgi                Medium   \n",
       "1          P08195        Plasma membrane             Very High   \n",
       "2          O43663  Large Protein Complex                  High   \n",
       "3          P51649          Mitochondrion                Medium   \n",
       "4          Q68EM7  Large Protein Complex             Very High   \n",
       "\n",
       "                                            Sequence  Sequence Lengh  \n",
       "0  MRLAGPLRIVVLVVSVGVTWIVVSILLGGPGSGFPRIQQLFTSPES...             230  \n",
       "1  MELQPPEASIAVVSIPRQLPGSHSEAGVQGLSAGDDSELGSHCVAQ...             630  \n",
       "2  MRRSEVLAEESIVCLQKALNHLREIWELIGIPEDQRLQRTEVVKKH...             620  \n",
       "3  MATCIWLRSCGARRLGSTFPGCRLRPRAGGLVPASGPAPGPAQLRC...             535  \n",
       "4  MKKQFNRMKQLANQTVGRAEKTEVLSEDLLQIERRLDTVRSICHHS...             881  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/strat_test.csv\", sep=\"\\t\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train[\"Compartment Prediction\"]\n",
    "test_y = test[\"Compartment Prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train[\"Sequence\"].copy()\n",
    "test_x = test[\"Sequence\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3871\n",
      "MKSNPAIQAAIDLTAGAAGGTACVLTGQPFDTMKVKMQTFPDLYRGLTDCCLKTYSQVGFRGFYKGTSPALIANIAENSVLFMCYGFCQQVVRKVAGLDKQAKLSDLQNAAAGSFASAFAALVLCPTELVKCRLQTMYEMETSGKIAKSQNTVWSVIKSILRKDGPLGFYHGLSSTLLREVPGYFFFFGGYELSRSFFASGRSKDELGPVPLMLSGGVGGICLWLAVYPVDCIKSRIQVLSMSGKQAGFIRTFINVVKNEGITALYSGLKPTMIRAFPANGALFLAYEYSRKLMMNQLEAY**\n"
     ]
    }
   ],
   "source": [
    "print(len(train_x))\n",
    "print(train_x[0]+'*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add * at the end of each sequence\n",
    "def end_adder(X):\n",
    "    for s in range(len(X)):\n",
    "        X.loc[s] += '*'\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = end_adder(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = end_adder(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501\n"
     ]
    }
   ],
   "source": [
    "max_len = len(max(train_x, key=len))\n",
    "print(max_len)\n",
    "# I checked that there is no longer sequence in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 sequences with U in dataset, replace buy Cys\n",
    "for x in range(len(train_x)):\n",
    "    seq =train_x[x]\n",
    "    train_x[x] = seq.replace('U', 'C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding of amino acids\n",
    "\n",
    "this was really helpfull:\n",
    "https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "MQNVINTVKGKA*\n"
     ]
    }
   ],
   "source": [
    "test_seq = \"MQNVINTVKGKA*\"\n",
    "\n",
    "# all amino acids (in blosum order)\n",
    "aa = \"ARNDCQEGHILKMFPSTWYV*\"\n",
    "tot_aa = len(aa)\n",
    "\n",
    "# define a mapping of aa to integers\n",
    "aa_to_int = dict((c, i) for i, c in enumerate(aa))\n",
    "int_to_aa = dict((i, c) for i, c in enumerate(aa))\n",
    "\n",
    "# one hot encode\n",
    "onehot_encoded = np.zeros((tot_aa, len(test_seq)))\n",
    "for a in range(len(test_seq)):\n",
    "    onehot_encoded[aa_to_int[test_seq[a]], a] = 1\n",
    "print(onehot_encoded)\n",
    "\n",
    "# One hot to aa\n",
    "new_seq = ''\n",
    "for a in range(len(onehot_encoded[1])):\n",
    "    vect = np.argmax(onehot_encoded[:,a])\n",
    "    new_seq += int_to_aa[vect]\n",
    "print(new_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['Actin binding proteins',\n",
    " 'ER',\n",
    " 'ER_high_curvature',\n",
    " 'Endosome',\n",
    " 'Ergic/cisGolgi',\n",
    " 'Golgi',\n",
    " 'Large Protein Complex',\n",
    " 'Lysosome',\n",
    " 'Mitochondrion',\n",
    " 'Nuclear pore complex',\n",
    " 'Peroxisome',\n",
    " 'Plasma membrane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3871,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_cat = len(cat)\n",
    "cat_to_int = {}\n",
    "int_to_cat = {}\n",
    "for i in range(tot_cat):\n",
    "    cat_to_int[cat[i]] = i\n",
    "    int_to_cat[i] = cat[i]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_indices(Y):\n",
    "    Y_indices = np.zeros([Y.shape[0],], dtype=int)\n",
    "    for i in range(len(Y)):\n",
    "        Y_indices[i] = cat_to_int[Y[i]]\n",
    "    return Y_indices\n",
    "\n",
    "# one hot encode\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_indices = cat_to_indices(train_y)\n",
    "test_y_indices = cat_to_indices(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_OH = convert_to_one_hot(train_y_indices, C = 12)\n",
    "test_y_OH = convert_to_one_hot(test_y_indices, C = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding of Protein sequences to list of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert sequences to array of indices. I will that that one for embedding \n",
    "\n",
    "def seq_to_indices(X, aa_to_int, max_len):\n",
    "    \"\"\"\n",
    "    Converts an array of senquences (strings) into an array of indices corresponding to aa in the sequence.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- array of sequences (strings), of shape (m, 1)\n",
    "    aa_to_int -- a dictionary containing the each aa mapped to its index\n",
    "    max_len -- maximum lengh of sequences array, bigger than test set \n",
    "    \n",
    "    Returns:\n",
    "    X_indices -- array of indices corresponding to aa in the sequences from X, of shape (m, max_len), padded\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (≈ 1 line)\n",
    "    X_indices = np.zeros([m,max_len])\n",
    "    X_indices.fill(aa_to_int[\"*\"])\n",
    "    \n",
    "    for i in range(m):                               # loop over training examples\n",
    "        seq_aa = X[i]\n",
    "        \n",
    "        # Initialize j to 0\n",
    "        j = 0\n",
    "        \n",
    "        # Loop over the words of sentence_words\n",
    "        for w in range(len(seq_aa)):\n",
    "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
    "            X_indices[i, j] = aa_to_int[seq_aa[w]]\n",
    "            # Increment j to j + 1\n",
    "            j = j+1\n",
    "            \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = seq_to_indices(train_x, aa_to_int, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12., 11., 15., ..., 20., 20., 20.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = seq_to_indices(test_x, aa_to_int, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this functiono convert all the sequences for train and test set directly to one hot encoding\n",
    "def OH_converter(X):\n",
    "    OH_X = []\n",
    "    for sequences in X:\n",
    "        seq = sequences\n",
    "        OH_seq = np.zeros((tot_aa, len(seq)))\n",
    "        for a in range(len(seq)):\n",
    "            OH_seq[aa_to_int[seq[a]], a] = 1\n",
    "        OH_X.append(OH_seq)\n",
    "    return OH_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_OH = OH_converter(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_OH = OH_converter(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to decode one OH_encoded sequence\n",
    "def OH_to_seq(data):\n",
    "    encoded_seq = data\n",
    "    seq = ''\n",
    "    for a in range(len(encoded_seq[1])):\n",
    "        vect = np.argmax(encoded_seq[:,a])\n",
    "        seq += int_to_aa[vect]\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MKSNPAIQAAIDLTAGAAGGTACVLTGQPFDTMKVKMQTFPDLYRGLTDCCLKTYSQVGFRGFYKGTSPALIANIAENSVLFMCYGFCQQVVRKVAGLDKQAKLSDLQNAAAGSFASAFAALVLCPTELVKCRLQTMYEMETSGKIAKSQNTVWSVIKSILRKDGPLGFYHGLSSTLLREVPGYFFFFGGYELSRSFFASGRSKDELGPVPLMLSGGVGGICLWLAVYPVDCIKSRIQVLSMSGKQAGFIRTFINVVKNEGITALYSGLKPTMIRAFPANGALFLAYEYSRKLMMNQLEAY**'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OH_to_seq(train_OH[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MKSNPAIQAAIDLTAGAAGGTACVLTGQPFDTMKVKMQTFPDLYRGLTDCCLKTYSQVGFRGFYKGTSPALIANIAENSVLFMCYGFCQQVVRKVAGLDKQAKLSDLQNAAAGSFASAFAALVLCPTELVKCRLQTMYEMETSGKIAKSQNTVWSVIKSILRKDGPLGFYHGLSSTLLREVPGYFFFFGGYELSRSFFASGRSKDELGPVPLMLSGGVGGICLWLAVYPVDCIKSRIQVLSMSGKQAGFIRTFINVVKNEGITALYSGLKPTMIRAFPANGALFLAYEYSRKLMMNQLEAY**'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLOSUM62 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_blosum(filename):\n",
    "    rows = []\n",
    "    data = []\n",
    "    with open(filename, \"r\") as fs:\n",
    "        line = fs.readline()\n",
    "        while line[0] == \"#\":\n",
    "            line = fs.readline()\n",
    "        for line in fs:\n",
    "            lspl = line.rstrip().replace('  ', ' ').split(' ')\n",
    "            rows.append(lspl[0])\n",
    "            data.append([float(i) for i in lspl[1:]])\n",
    "    data = np.asarray(data)\n",
    "    # Remove Z X B rows and colums\n",
    "    data = np.delete(data, [20, 21, 22], axis=0)\n",
    "    data = np.delete(data, [20, 21, 22], axis=1)\n",
    "    del rows[20:23]\n",
    "    return(data, rows)\n",
    "\n",
    "blosum, rows = read_blosum(\"data/BLOSUM62.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape:    (21, 21)\n",
      "transformed shape: (21, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(blosum)\n",
    "blosum_pca = pca.transform(blosum)\n",
    "print(\"original shape:   \", blosum.shape)\n",
    "print(\"transformed shape:\", blosum_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.scatter(blosum_pca[:, 0], blosum_pca[:, 1], edgecolor='none')\n",
    "\n",
    "for i, txt in enumerate(rows):\n",
    "    ax.annotate(txt, (blosum_pca[:, 0][i], blosum_pca[:, 1][i]))\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = blosum[:, :]   # foo[:, -1] for the last column\n",
    "blosum[:, :] = (v - v.min()) / (v.max() - v.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "blosum_dict = {}\n",
    "for i in range(len(rows)):\n",
    "    blosum_dict[rows[i]]= blosum[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': array([0.53333333, 0.2       , 0.13333333, 0.13333333, 0.26666667,\n",
       "        0.2       , 0.2       , 0.26666667, 0.13333333, 0.2       ,\n",
       "        0.2       , 0.2       , 0.2       , 0.13333333, 0.2       ,\n",
       "        0.33333333, 0.26666667, 0.06666667, 0.13333333, 0.26666667,\n",
       "        0.        ]),\n",
       " 'R': array([0.2       , 0.6       , 0.26666667, 0.13333333, 0.06666667,\n",
       "        0.33333333, 0.26666667, 0.13333333, 0.26666667, 0.06666667,\n",
       "        0.13333333, 0.4       , 0.2       , 0.06666667, 0.13333333,\n",
       "        0.2       , 0.2       , 0.06666667, 0.13333333, 0.06666667,\n",
       "        0.        ]),\n",
       " 'N': array([0.13333333, 0.26666667, 0.66666667, 0.33333333, 0.06666667,\n",
       "        0.26666667, 0.26666667, 0.26666667, 0.33333333, 0.06666667,\n",
       "        0.06666667, 0.26666667, 0.13333333, 0.06666667, 0.13333333,\n",
       "        0.33333333, 0.26666667, 0.        , 0.13333333, 0.06666667,\n",
       "        0.        ]),\n",
       " 'D': array([0.13333333, 0.13333333, 0.33333333, 0.66666667, 0.06666667,\n",
       "        0.26666667, 0.4       , 0.2       , 0.2       , 0.06666667,\n",
       "        0.        , 0.2       , 0.06666667, 0.06666667, 0.2       ,\n",
       "        0.26666667, 0.2       , 0.        , 0.06666667, 0.06666667,\n",
       "        0.        ]),\n",
       " 'C': array([0.26666667, 0.06666667, 0.06666667, 0.06666667, 0.86666667,\n",
       "        0.06666667, 0.        , 0.06666667, 0.06666667, 0.2       ,\n",
       "        0.2       , 0.06666667, 0.2       , 0.13333333, 0.06666667,\n",
       "        0.2       , 0.2       , 0.13333333, 0.13333333, 0.2       ,\n",
       "        0.        ]),\n",
       " 'Q': array([0.2       , 0.33333333, 0.26666667, 0.26666667, 0.06666667,\n",
       "        0.6       , 0.4       , 0.13333333, 0.26666667, 0.06666667,\n",
       "        0.13333333, 0.33333333, 0.26666667, 0.06666667, 0.2       ,\n",
       "        0.26666667, 0.2       , 0.13333333, 0.2       , 0.13333333,\n",
       "        0.        ]),\n",
       " 'E': array([0.2       , 0.26666667, 0.26666667, 0.4       , 0.        ,\n",
       "        0.4       , 0.6       , 0.13333333, 0.26666667, 0.06666667,\n",
       "        0.06666667, 0.33333333, 0.13333333, 0.06666667, 0.2       ,\n",
       "        0.26666667, 0.2       , 0.06666667, 0.13333333, 0.13333333,\n",
       "        0.        ]),\n",
       " 'G': array([0.26666667, 0.13333333, 0.26666667, 0.2       , 0.06666667,\n",
       "        0.13333333, 0.13333333, 0.66666667, 0.13333333, 0.        ,\n",
       "        0.        , 0.13333333, 0.06666667, 0.06666667, 0.13333333,\n",
       "        0.26666667, 0.13333333, 0.13333333, 0.06666667, 0.06666667,\n",
       "        0.        ]),\n",
       " 'H': array([0.13333333, 0.26666667, 0.33333333, 0.2       , 0.06666667,\n",
       "        0.26666667, 0.26666667, 0.13333333, 0.8       , 0.06666667,\n",
       "        0.06666667, 0.2       , 0.13333333, 0.2       , 0.13333333,\n",
       "        0.2       , 0.13333333, 0.13333333, 0.4       , 0.06666667,\n",
       "        0.        ]),\n",
       " 'I': array([0.2       , 0.06666667, 0.06666667, 0.06666667, 0.2       ,\n",
       "        0.06666667, 0.06666667, 0.        , 0.06666667, 0.53333333,\n",
       "        0.4       , 0.06666667, 0.33333333, 0.26666667, 0.06666667,\n",
       "        0.13333333, 0.2       , 0.06666667, 0.2       , 0.46666667,\n",
       "        0.        ]),\n",
       " 'L': array([0.2       , 0.13333333, 0.06666667, 0.        , 0.2       ,\n",
       "        0.13333333, 0.06666667, 0.        , 0.06666667, 0.4       ,\n",
       "        0.53333333, 0.13333333, 0.4       , 0.26666667, 0.06666667,\n",
       "        0.13333333, 0.2       , 0.13333333, 0.2       , 0.33333333,\n",
       "        0.        ]),\n",
       " 'K': array([0.2       , 0.4       , 0.26666667, 0.2       , 0.06666667,\n",
       "        0.33333333, 0.33333333, 0.13333333, 0.2       , 0.06666667,\n",
       "        0.13333333, 0.6       , 0.2       , 0.06666667, 0.2       ,\n",
       "        0.26666667, 0.2       , 0.06666667, 0.13333333, 0.13333333,\n",
       "        0.        ]),\n",
       " 'M': array([0.2       , 0.2       , 0.13333333, 0.06666667, 0.2       ,\n",
       "        0.26666667, 0.13333333, 0.06666667, 0.13333333, 0.33333333,\n",
       "        0.4       , 0.2       , 0.6       , 0.26666667, 0.13333333,\n",
       "        0.2       , 0.2       , 0.2       , 0.2       , 0.33333333,\n",
       "        0.        ]),\n",
       " 'F': array([0.13333333, 0.06666667, 0.06666667, 0.06666667, 0.13333333,\n",
       "        0.06666667, 0.06666667, 0.06666667, 0.2       , 0.26666667,\n",
       "        0.26666667, 0.06666667, 0.26666667, 0.66666667, 0.        ,\n",
       "        0.13333333, 0.13333333, 0.33333333, 0.46666667, 0.2       ,\n",
       "        0.        ]),\n",
       " 'P': array([0.2       , 0.13333333, 0.13333333, 0.2       , 0.06666667,\n",
       "        0.2       , 0.2       , 0.13333333, 0.13333333, 0.06666667,\n",
       "        0.06666667, 0.2       , 0.13333333, 0.        , 0.73333333,\n",
       "        0.2       , 0.2       , 0.        , 0.06666667, 0.13333333,\n",
       "        0.        ]),\n",
       " 'S': array([0.33333333, 0.2       , 0.33333333, 0.26666667, 0.2       ,\n",
       "        0.26666667, 0.26666667, 0.26666667, 0.2       , 0.13333333,\n",
       "        0.13333333, 0.26666667, 0.2       , 0.13333333, 0.2       ,\n",
       "        0.53333333, 0.33333333, 0.06666667, 0.13333333, 0.13333333,\n",
       "        0.        ]),\n",
       " 'T': array([0.26666667, 0.2       , 0.26666667, 0.2       , 0.2       ,\n",
       "        0.2       , 0.2       , 0.13333333, 0.13333333, 0.2       ,\n",
       "        0.2       , 0.2       , 0.2       , 0.13333333, 0.2       ,\n",
       "        0.33333333, 0.6       , 0.13333333, 0.13333333, 0.26666667,\n",
       "        0.        ]),\n",
       " 'W': array([0.06666667, 0.06666667, 0.        , 0.        , 0.13333333,\n",
       "        0.13333333, 0.06666667, 0.13333333, 0.13333333, 0.06666667,\n",
       "        0.13333333, 0.06666667, 0.2       , 0.33333333, 0.        ,\n",
       "        0.06666667, 0.13333333, 1.        , 0.4       , 0.06666667,\n",
       "        0.        ]),\n",
       " 'Y': array([0.13333333, 0.13333333, 0.13333333, 0.06666667, 0.13333333,\n",
       "        0.2       , 0.13333333, 0.06666667, 0.4       , 0.2       ,\n",
       "        0.2       , 0.13333333, 0.2       , 0.46666667, 0.06666667,\n",
       "        0.13333333, 0.13333333, 0.4       , 0.73333333, 0.2       ,\n",
       "        0.        ]),\n",
       " 'V': array([0.26666667, 0.06666667, 0.06666667, 0.06666667, 0.2       ,\n",
       "        0.13333333, 0.13333333, 0.06666667, 0.06666667, 0.46666667,\n",
       "        0.33333333, 0.13333333, 0.33333333, 0.2       , 0.13333333,\n",
       "        0.13333333, 0.26666667, 0.06666667, 0.2       , 0.53333333,\n",
       "        0.        ]),\n",
       " '*': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.33333333])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blosum_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam, Nadam\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(blosum_dict, aa_to_int):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer based on Blosum62\n",
    "    \n",
    "    Arguments:\n",
    "    blosum_dict -- dictionary mapping aa to their Blosum62 representation.\n",
    "    aa_to_int -- dictionary mapping from amino acid to their indices \n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "    \n",
    "    aa_len = len(aa_to_int) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
    "    emb_dim = blosum_dict[\"A\"].shape[0]      # define dimensionality of your blosum vectors \n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize the embedding matrix as a numpy array of zeros of shape (aa_len, dimensions of aa vectors = emb_dim)\n",
    "    emb_matrix = np.zeros([aa_len,emb_dim])\n",
    "    \n",
    "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
    "    for aa, index in aa_to_int.items():\n",
    "        emb_matrix[index, :] = blosum_dict[aa]\n",
    "\n",
    "    # Define Keras embedding layer with the correct output/input sizes, make it trainable. Use Embedding(...). Make sure to set trainable=False. \n",
    "    embedding_layer = Embedding(aa_len, emb_dim, trainable=False)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the \"None\".\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/julie/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "weights[0][1][3] = 0.13333334\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = pretrained_embedding_layer(blosum_dict, aa_to_int)\n",
    "print(\"weights[0][1][3] =\", embedding_layer.get_weights()[0][1][3])\n",
    "# How to check it's fine? \n",
    "# I could also try to train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: Emojify_V2\n",
    "\n",
    "def Loc_predict(input_shape, blosum_dict, aa_to_int):\n",
    "    \"\"\"\n",
    "    Function creating the a protein localization prediction model's graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    blosum_dict -- dictionary mapping everyaa into its blosum vector representation\n",
    "    aa_to_int -- dictionary mapping from aa to their indices \n",
    "    \n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).\n",
    "    aa_indices = Input(input_shape, dtype='int32')\n",
    "    \n",
    "    # Create the embedding layer pretrained with GloVe Vectors (≈1 line)\n",
    "    embedding_layer = pretrained_embedding_layer(blosum_dict, aa_to_int)\n",
    "    \n",
    "    # Propagate sentence_indices through your embedding layer, you get back the embeddings\n",
    "    embeddings = embedding_layer(aa_indices)\n",
    "    #embeddings = Embedding(input_shape, 30)\n",
    "    \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a batch of sequences.\n",
    "    #X =  LSTM(64, return_sequences=True)(embeddings)\n",
    "    X = Bidirectional(LSTM(64, return_sequences=True))(embeddings)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    #X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a single hidden state, not a batch of sequences.\n",
    "    X = LSTM(64, return_sequences=False)(X)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    #X = Dropout(0.5)(X)\n",
    "    X = Dense(128, activation='relu')(X)\n",
    "    X = Dense(128, activation='relu')(X)\n",
    "    # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.\n",
    "    X = Dense(12, activation='softmax')(X)\n",
    "    # Add a softmax activation\n",
    "    # X = Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs=[aa_indices], outputs=[X])\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 1501)              0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 1501, 21)          462       \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 1501, 128)         44032     \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 120,282\n",
      "Trainable params: 119,820\n",
      "Non-trainable params: 462\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Loc_predict((max_len,), blosum_dict, aa_to_int)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.metrics import categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Nadam(learning_rate=1.0), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train_y),\n",
    "                                                 train_y)\n",
    "d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3871/3871 [==============================] - 168s 43ms/step - loss: 2.6197 - accuracy: 0.0571\n",
      "Epoch 2/50\n",
      "3871/3871 [==============================] - 175s 45ms/step - loss: 2.5899 - accuracy: 0.0506\n",
      "Epoch 3/50\n",
      "3871/3871 [==============================] - 163s 42ms/step - loss: 2.6089 - accuracy: 0.0778\n",
      "Epoch 4/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.6238 - accuracy: 0.0514\n",
      "Epoch 5/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.6692 - accuracy: 0.0470\n",
      "Epoch 6/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.6268 - accuracy: 0.0429\n",
      "Epoch 7/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.6162 - accuracy: 0.0486\n",
      "Epoch 8/50\n",
      "3871/3871 [==============================] - 172s 44ms/step - loss: 2.6021 - accuracy: 0.0349\n",
      "Epoch 9/50\n",
      "3871/3871 [==============================] - 163s 42ms/step - loss: 2.5989 - accuracy: 0.0672\n",
      "Epoch 10/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.6046 - accuracy: 0.0325\n",
      "Epoch 11/50\n",
      "3871/3871 [==============================] - 164s 42ms/step - loss: 2.6013 - accuracy: 0.0437\n",
      "Epoch 12/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.6156 - accuracy: 0.0599\n",
      "Epoch 13/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.6137 - accuracy: 0.0517\n",
      "Epoch 14/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.6233 - accuracy: 0.0584\n",
      "Epoch 15/50\n",
      "3871/3871 [==============================] - 169s 44ms/step - loss: 2.6471 - accuracy: 0.0708\n",
      "Epoch 16/50\n",
      "3871/3871 [==============================] - 170s 44ms/step - loss: 2.6516 - accuracy: 0.0542\n",
      "Epoch 17/50\n",
      "3871/3871 [==============================] - 165s 43ms/step - loss: 2.6135 - accuracy: 0.0488\n",
      "Epoch 18/50\n",
      "3871/3871 [==============================] - 164s 42ms/step - loss: 2.5952 - accuracy: 0.0253\n",
      "Epoch 19/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.6224 - accuracy: 0.0480\n",
      "Epoch 20/50\n",
      "3871/3871 [==============================] - 163s 42ms/step - loss: 2.6208 - accuracy: 0.0369\n",
      "Epoch 21/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.6345 - accuracy: 0.0584\n",
      "Epoch 22/50\n",
      "3871/3871 [==============================] - 163s 42ms/step - loss: 2.6099 - accuracy: 0.0455\n",
      "Epoch 23/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.6141 - accuracy: 0.0718\n",
      "Epoch 24/50\n",
      "3871/3871 [==============================] - 170s 44ms/step - loss: 2.5853 - accuracy: 0.0284\n",
      "Epoch 25/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.6086 - accuracy: 0.0269\n",
      "Epoch 26/50\n",
      "3871/3871 [==============================] - 163s 42ms/step - loss: 2.6017 - accuracy: 0.0462\n",
      "Epoch 27/50\n",
      "3871/3871 [==============================] - 163s 42ms/step - loss: 2.6413 - accuracy: 0.0362\n",
      "Epoch 28/50\n",
      "3871/3871 [==============================] - 163s 42ms/step - loss: 2.6043 - accuracy: 0.0553\n",
      "Epoch 29/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.5946 - accuracy: 0.0561\n",
      "Epoch 30/50\n",
      "3871/3871 [==============================] - 163s 42ms/step - loss: 2.5888 - accuracy: 0.0568\n",
      "Epoch 31/50\n",
      "3871/3871 [==============================] - 169s 44ms/step - loss: 2.5958 - accuracy: 0.0235\n",
      "Epoch 32/50\n",
      "3871/3871 [==============================] - 164s 42ms/step - loss: 2.6009 - accuracy: 0.0592\n",
      "Epoch 33/50\n",
      "3871/3871 [==============================] - 164s 42ms/step - loss: 2.6087 - accuracy: 0.0571\n",
      "Epoch 34/50\n",
      "3871/3871 [==============================] - 163s 42ms/step - loss: 2.5903 - accuracy: 0.0320\n",
      "Epoch 35/50\n",
      "3871/3871 [==============================] - 163s 42ms/step - loss: 2.6294 - accuracy: 0.0302\n",
      "Epoch 36/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.5810 - accuracy: 0.0429\n",
      "Epoch 37/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.5768 - accuracy: 0.0377\n",
      "Epoch 38/50\n",
      "3871/3871 [==============================] - 164s 42ms/step - loss: 2.5969 - accuracy: 0.0408\n",
      "Epoch 39/50\n",
      "3871/3871 [==============================] - 170s 44ms/step - loss: 2.5656 - accuracy: 0.0452\n",
      "Epoch 40/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.6447 - accuracy: 0.0677\n",
      "Epoch 41/50\n",
      "3871/3871 [==============================] - 162s 42ms/step - loss: 2.5972 - accuracy: 0.0646\n",
      "Epoch 42/50\n",
      "3871/3871 [==============================] - 339s 88ms/step - loss: 2.6094 - accuracy: 0.0871\n",
      "Epoch 43/50\n",
      " 384/3871 [=>............................] - ETA: 5:54 - loss: 2.8688 - accuracy: 0.0208"
     ]
    }
   ],
   "source": [
    "model.fit(train_indices, train_y_OH, epochs = 50, batch_size = 128, shuffle=True, class_weight=d_class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
