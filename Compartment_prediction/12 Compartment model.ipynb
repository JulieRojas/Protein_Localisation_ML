{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "from sklearn.utils import class_weight\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/12C_train.csv\", sep=\"\\t\")\n",
    "valid = pd.read_csv(\"data/12C_valid.csv\", sep=\"\\t\")\n",
    "\n",
    "y_train = train[\"Compartment Prediction\"]\n",
    "y_valid = valid[\"Compartment Prediction\"]\n",
    "\n",
    "x_train = train[\"Sequence\"].copy()\n",
    "x_valid = valid[\"Sequence\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3496 train sequences\n",
      "617 test sequences\n"
     ]
    }
   ],
   "source": [
    "max_features = 2000\n",
    "# cut texts after this number of words\n",
    "# (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_valid), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_adder(X):\n",
    "    for s in range(len(X)):\n",
    "        X.loc[s] += '*'\n",
    "    return X\n",
    "\n",
    "x_train = end_adder(x_train)\n",
    "x_valid = end_adder(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501\n"
     ]
    }
   ],
   "source": [
    "max_len = len(max(x_train, key=len))\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all amino acids (in blosum order)\n",
    "aa = \"ARNDCQEGHILKMFPSTWYVU*\"\n",
    "tot_aa = len(aa)\n",
    "\n",
    "# define a mapping of aa to integers\n",
    "aa_to_int = dict((c, i) for i, c in enumerate(aa))\n",
    "int_to_aa = dict((i, c) for i, c in enumerate(aa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Actin binding proteins',\n",
       " 'ER',\n",
       " 'ER_high_curvature',\n",
       " 'Endosome',\n",
       " 'Ergic/cisGolgi',\n",
       " 'Golgi',\n",
       " 'Large Protein Complex',\n",
       " 'Lysosome',\n",
       " 'Mitochondrion',\n",
       " 'Nuclear pore complex',\n",
       " 'Peroxisome',\n",
       " 'Plasma membrane'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['Actin binding proteins',\n",
    " 'ER',\n",
    " 'ER_high_curvature',\n",
    " 'Endosome',\n",
    " 'Ergic/cisGolgi',\n",
    " 'Golgi',\n",
    " 'Large Protein Complex',\n",
    " 'Lysosome',\n",
    " 'Mitochondrion',\n",
    " 'Nuclear pore complex',\n",
    " 'Peroxisome',\n",
    " 'Plasma membrane']\n",
    "\n",
    "tot_cat = len(cat)\n",
    "cat_to_int = {}\n",
    "int_to_cat = {}\n",
    "for i in range(tot_cat):\n",
    "    cat_to_int[cat[i]] = i\n",
    "    int_to_cat[i] = cat[i]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_indices(Y):\n",
    "    Y_indices = np.zeros([Y.shape[0],], dtype=int)\n",
    "    for i in range(len(Y)):\n",
    "        Y_indices[i] = cat_to_int[Y[i]]\n",
    "    return Y_indices\n",
    "\n",
    "# one hot encode\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_indices = cat_to_indices(y_train)\n",
    "y_valid_indices = cat_to_indices(y_valid)\n",
    "\n",
    "y_train_OH = convert_to_one_hot(y_train_indices, C = tot_cat)\n",
    "y_valid_OH = convert_to_one_hot(y_valid_indices, C = tot_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_train processing: \n",
    "### From Sequences to list of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert sequences to array of indices. I will that that one for embedding \n",
    "\n",
    "def seq_to_indices(X, aa_to_int, max_len):\n",
    "    \n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (â‰ˆ 1 line)\n",
    "    X_indices = []\n",
    "    \n",
    "    for i in range(m):                               # loop over training examples\n",
    "        seq_aa = X[i]\n",
    "        seq_ind = []\n",
    "        \n",
    "        # Loop over the words of sentence_words\n",
    "        for w in range(len(seq_aa)):\n",
    "            seq_ind.append(aa_to_int[seq_aa[w]])\n",
    "            \n",
    "        X_indices.append(seq_ind)\n",
    "            \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_indices = seq_to_indices(x_train, aa_to_int, max_len)\n",
    "x_valid_indices = seq_to_indices(x_valid, aa_to_int, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (3496, 1501)\n",
      "x_valid shape: (617, 1501)\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences\n",
    "# By default, the padding is added before the sequence\n",
    "x_train_pad = sequence.pad_sequences(x_train_indices, maxlen=max_len, value=aa_to_int[\"*\"])\n",
    "x_valid_pad = sequence.pad_sequences(x_valid_indices, maxlen=max_len, value=aa_to_int[\"*\"])\n",
    "print('x_train shape:', x_train_pad.shape)\n",
    "print('x_valid shape:', x_valid_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot to label \n",
    "#Y is list of OH vector\n",
    "def OH_to_label_indices(Y):\n",
    "    labels = []\n",
    "    for a in Y:\n",
    "        indices = np.argmax(a)\n",
    "        labels.append(indices)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_cat(Y):\n",
    "    Y_cat = []\n",
    "    for i in range(len(Y)):\n",
    "        Y_cat.append(int_to_cat[Y[i]])\n",
    "    return Y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/julie/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train...\n",
      "WARNING:tensorflow:From /home/julie/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3496 samples, validate on 617 samples\n",
      "Epoch 1/25\n",
      "3496/3496 [==============================] - 515s 147ms/step - loss: 1.7197 - accuracy: 0.4931 - val_loss: 1.7036 - val_accuracy: 0.4976\n",
      "\n",
      "Epoch 00001: saving model to models/weights.01-1.70.hdf5\n",
      "Epoch 2/25\n",
      "3496/3496 [==============================] - 444s 127ms/step - loss: 1.6580 - accuracy: 0.4974 - val_loss: 1.6400 - val_accuracy: 0.4976\n",
      "\n",
      "Epoch 00002: saving model to models/weights.02-1.64.hdf5\n",
      "Epoch 3/25\n",
      "3496/3496 [==============================] - 490s 140ms/step - loss: 1.6258 - accuracy: 0.4974 - val_loss: 1.6156 - val_accuracy: 0.4992\n",
      "\n",
      "Epoch 00003: saving model to models/weights.03-1.62.hdf5\n",
      "Epoch 4/25\n",
      "3496/3496 [==============================] - 485s 139ms/step - loss: 1.6059 - accuracy: 0.5037 - val_loss: 1.6329 - val_accuracy: 0.5219\n",
      "\n",
      "Epoch 00004: saving model to models/weights.04-1.63.hdf5\n",
      "Epoch 5/25\n",
      "3496/3496 [==============================] - 507s 145ms/step - loss: 1.5861 - accuracy: 0.5054 - val_loss: 1.5893 - val_accuracy: 0.5203\n",
      "\n",
      "Epoch 00005: saving model to models/weights.05-1.59.hdf5\n",
      "Epoch 6/25\n",
      "3496/3496 [==============================] - 500s 143ms/step - loss: 1.5575 - accuracy: 0.5166 - val_loss: 1.5673 - val_accuracy: 0.5332\n",
      "\n",
      "Epoch 00006: saving model to models/weights.06-1.57.hdf5\n",
      "Epoch 7/25\n",
      "3496/3496 [==============================] - 497s 142ms/step - loss: 1.5461 - accuracy: 0.5246 - val_loss: 1.5403 - val_accuracy: 0.5332\n",
      "\n",
      "Epoch 00007: saving model to models/weights.07-1.54.hdf5\n",
      "Epoch 8/25\n",
      "3496/3496 [==============================] - 531s 152ms/step - loss: 1.5429 - accuracy: 0.5209 - val_loss: 1.5500 - val_accuracy: 0.5284\n",
      "\n",
      "Epoch 00008: saving model to models/weights.08-1.55.hdf5\n",
      "Epoch 9/25\n",
      "3496/3496 [==============================] - 532s 152ms/step - loss: 1.4929 - accuracy: 0.5352 - val_loss: 1.5270 - val_accuracy: 0.5494\n",
      "\n",
      "Epoch 00009: saving model to models/weights.09-1.53.hdf5\n",
      "Epoch 10/25\n",
      "3496/3496 [==============================] - 414s 118ms/step - loss: 1.4412 - accuracy: 0.5595 - val_loss: 1.3947 - val_accuracy: 0.5478\n",
      "\n",
      "Epoch 00010: saving model to models/weights.10-1.39.hdf5\n",
      "Epoch 11/25\n",
      "3496/3496 [==============================] - 414s 118ms/step - loss: 1.3505 - accuracy: 0.5895 - val_loss: 1.3474 - val_accuracy: 0.6305\n",
      "\n",
      "Epoch 00011: saving model to models/weights.11-1.35.hdf5\n",
      "Epoch 12/25\n",
      "3496/3496 [==============================] - 476s 136ms/step - loss: 1.2926 - accuracy: 0.6098 - val_loss: 1.3396 - val_accuracy: 0.6143\n",
      "\n",
      "Epoch 00012: saving model to models/weights.12-1.34.hdf5\n",
      "Epoch 13/25\n",
      "3496/3496 [==============================] - 462s 132ms/step - loss: 1.2410 - accuracy: 0.6293 - val_loss: 1.2998 - val_accuracy: 0.6256\n",
      "\n",
      "Epoch 00013: saving model to models/weights.13-1.30.hdf5\n",
      "Epoch 14/25\n",
      "3496/3496 [==============================] - 505s 145ms/step - loss: 1.1904 - accuracy: 0.6462 - val_loss: 1.1811 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00014: saving model to models/weights.14-1.18.hdf5\n",
      "Epoch 15/25\n",
      "3496/3496 [==============================] - 557s 159ms/step - loss: 1.1376 - accuracy: 0.6608 - val_loss: 1.1449 - val_accuracy: 0.6840\n",
      "\n",
      "Epoch 00015: saving model to models/weights.15-1.14.hdf5\n",
      "Epoch 16/25\n",
      "3496/3496 [==============================] - 723s 207ms/step - loss: 1.0960 - accuracy: 0.6799 - val_loss: 1.1817 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00016: saving model to models/weights.16-1.18.hdf5\n",
      "Epoch 17/25\n",
      "3496/3496 [==============================] - 787s 225ms/step - loss: 1.0687 - accuracy: 0.6836 - val_loss: 1.1440 - val_accuracy: 0.6921\n",
      "\n",
      "Epoch 00017: saving model to models/weights.17-1.14.hdf5\n",
      "Epoch 18/25\n",
      "3496/3496 [==============================] - 712s 204ms/step - loss: 1.0092 - accuracy: 0.7085 - val_loss: 1.1056 - val_accuracy: 0.6985\n",
      "\n",
      "Epoch 00018: saving model to models/weights.18-1.11.hdf5\n",
      "Epoch 19/25\n",
      "3496/3496 [==============================] - 717s 205ms/step - loss: 0.9878 - accuracy: 0.7080 - val_loss: 1.1567 - val_accuracy: 0.6807\n",
      "\n",
      "Epoch 00019: saving model to models/weights.19-1.16.hdf5\n",
      "Epoch 20/25\n",
      "3496/3496 [==============================] - 725s 207ms/step - loss: 0.9485 - accuracy: 0.7160 - val_loss: 1.1328 - val_accuracy: 0.6921\n",
      "\n",
      "Epoch 00020: saving model to models/weights.20-1.13.hdf5\n",
      "Epoch 21/25\n",
      "3496/3496 [==============================] - 742s 212ms/step - loss: 0.9177 - accuracy: 0.7200 - val_loss: 1.1679 - val_accuracy: 0.6661\n",
      "\n",
      "Epoch 00021: saving model to models/weights.21-1.17.hdf5\n",
      "Epoch 22/25\n",
      "3496/3496 [==============================] - 659s 188ms/step - loss: 0.8718 - accuracy: 0.7360 - val_loss: 1.2846 - val_accuracy: 0.6418\n",
      "\n",
      "Epoch 00022: saving model to models/weights.22-1.28.hdf5\n",
      "Epoch 23/25\n",
      "3496/3496 [==============================] - 558s 160ms/step - loss: 0.8355 - accuracy: 0.7477 - val_loss: 1.1949 - val_accuracy: 0.6921\n",
      "\n",
      "Epoch 00023: saving model to models/weights.23-1.19.hdf5\n",
      "Epoch 24/25\n",
      "3496/3496 [==============================] - 574s 164ms/step - loss: 0.7962 - accuracy: 0.7554 - val_loss: 1.2247 - val_accuracy: 0.6985\n",
      "\n",
      "Epoch 00024: saving model to models/weights.24-1.22.hdf5\n",
      "Epoch 25/25\n",
      "3496/3496 [==============================] - 555s 159ms/step - loss: 0.7446 - accuracy: 0.7663 - val_loss: 1.2226 - val_accuracy: 0.6791\n",
      "\n",
      "Epoch 00025: saving model to models/weights.25-1.22.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f3351e01908>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=max_len))\n",
    "model.add(Bidirectional(LSTM(128, dropout = 0.2, recurrent_dropout= 0.2)))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile('Nadam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='models/weights.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only=False)\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train_pad, y_train_OH,\n",
    "          batch_size=batch_size,\n",
    "          epochs=25, class_weight= class_weights,            \n",
    "          validation_data=[x_valid_pad, y_valid_OH],\n",
    "          callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "y_pred = model.predict(x_valid_pad)\n",
    "y_pred_indices = OH_to_label_indices(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mx = confusion_matrix(y_valid_indices, y_pred_indices)\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Actin binding proteins',\n",
       " 'ER',\n",
       " 'ER_high_curvature',\n",
       " 'Endosome',\n",
       " 'Ergic/cisGolgi',\n",
       " 'Golgi',\n",
       " 'Large Protein Complex',\n",
       " 'Lysosome',\n",
       " 'Mitochondrion',\n",
       " 'Nuclear pore complex',\n",
       " 'Peroxisome',\n",
       " 'Plasma membrane']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1501, 128)         256000    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 527,788\n",
      "Trainable params: 527,788\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "best_model = load_model('models/weights.18-1.11.hdf5')\n",
    "# summarize model.\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(x_valid_pad)\n",
    "y_pred_indices = OH_to_label_indices(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAC6tJREFUeJzt3V+IZvV9x/H3x5ldddcuKjbBqK0GJK0EimEpJsIiMRe2kepFAykoNgT2pk00tATbGy/bixCSixJYrIlQsYSNNCIlf7AB76SrBqJuSoJpdJONq4hRF3H/fXsxz37ZDpp5dp7jc87o+wUyM4+Pv+fLzPiec86ccyZVhSQBnDP2AJKmwyBIagZBUjMIkppBkNQMgqQ2qSAkuSnJ/yT5eZK7JzDPFUl+lORgkmeS3Dn2TKclWUnyVJJHxp4FIMmFSfYn+ens8/XxCcz0pdnX7ekkDyY5b6Q57ktyJMnTZzx2cZIfJvnZ7O1FY8y23mSCkGQF+Bfgz4BrgL9Kcs24U3EC+Luq+mPgOuBvJjDTaXcCB8ce4gxfB75XVX8E/Akjz5bkMuCLwO6q+iiwAnx2pHG+Bdy07rG7gUer6mrg0dnHo5tMEIA/BX5eVc9V1THg34Fbxhyoqg5X1ZOz919n7Zv8sjFnAkhyOfBp4N6xZwFIsgvYA/wrQFUdq6pXx50KgFXg/CSrwA7g12MMUVWPAa+se/gW4P7Z+/cDty51qHcwpSBcBrxwxseHmMD/fKcluRK4Fnh83EkA+BrwZeDU2IPMfBh4CfjmbDfm3iQ7xxyoqn4FfAV4HjgM/LaqfjDmTOt8sKoOw9oPHuADI88DTCsIeZvHJnFedZILgO8Ad1XVayPPcjNwpKqeGHOOdVaBjwHfqKprgaOMvAk82ye/BbgK+BCwM8ltY860FUwpCIeAK874+HJG2sQ7U5JtrMXggap6aOx5gOuBv0jyv6ztVn0yyb+NOxKHgENVdXrraT9rgRjTp4BfVNVLVXUceAj4xMgznenFJJcCzN4eGXkeYFpB+G/g6iRXJdnO2gGgh8ccKElY2y8+WFVfHXOW06rqH6rq8qq6krXP0X9V1ag/+arqN8ALST4ye+hG4NkRR4K1XYXrkuyYfR1vZFoHYR8G7pi9fwfw3RFnaatjD3BaVZ1I8rfA91k7InxfVT0z8ljXA7cDP0ny49lj/1hV/zniTFP1BeCBWcyfAz435jBV9XiS/cCTrP226Clg3xizJHkQuAG4JMkh4B7gn4FvJ/k8a/H6zBizrRcvf5Z02pR2GSSNzCBIagZBUjMIkppBkNQmF4Qke8eeYb0pzgTTnMuZ5jPFmWCCQQCm+Ima4kwwzbmcaT5TnGmSQZA0kqWemJTEs6C2sLUzgH+3qpr7eVquqtrwCzOZU5c1fdu2bRtsrWPHjg22lobjLoOkZhAkNYMgqRkESW2hIEzttumSFrPpIEz0tumSFrDIFsLkbpsuaTGLBGGu26Yn2ZvkQJIDC7yWpCVY5MSkuW6bXlX7mN3LzjMVpWlbZAthkrdNl7R5iwRhcrdNl7SYTe8yTPS26ZIW4NWOmtv27dsHW8uLm5ZvnqsdPVNRUjMIkppBkNS27DGEa64Z5izpZ58d7m+SznOnoHl5R6H5vNc/5zt37hxknTfffJOTJ096DEHS/AyCpGYQJDWDIKkZBEnNIEhqBkFSMwiSmkGQ1AyCpGYQJDWDIKkZBEnNIEhqBkFSMwiSmkGQ1LbsHZOGulPOFO+SM1XnnDPcz49Tp04Ntpbm412XJZ0VgyCpGQRJzSBIagZBUjMIktqmg5DkiiQ/SnIwyTNJ7hxyMEnLt+nzEJJcClxaVU8m+T3gCeDWqnrHP4XkeQhbm+chbG3v6nkIVXW4qp6cvf86cBC4bLPrSRrfIMlPciVwLfD4EOtJGsfqogskuQD4DnBXVb32Nv9+L7B30deR9O5b6FqGJNuAR4DvV9VX53i+xxC2MI8hbG3zHENY5KBigPuBV6rqrjn/G4OwhRmEre3dvrjpeuB24JNJfjz7588XWE/SyLz82S2EubmFsLV5+bOks2IQJDWDIKktfB7CWIbanz158uQg67wfXHzxxYOt9fLLLw+21nvZ9u3bB1nn+PHjcz3PLQRJzSBIagZBUjMIkppBkNQMgqRmECQ1gyCpGQRJzSBIagZBUjMIkppBkNQMgqRmECQ1gyCpGQRJzSBIalv2NuwrKyuDrOMt1ObnbdiXb8g/N+Bt2CWdFYMgqRkESc0gSGoGQVJbOAhJVpI8leSRIQaSNJ4hthDuBA4OsI6kkS0UhCSXA58G7h1mHEljWnQL4WvAlwHPMpHeAzYdhCQ3A0eq6okNnrc3yYEkBzb7WpKWY9OnLif5J+B24ARwHrALeKiqbvsd/42nLm9hnrq8fMs+dXmQaxmS3AD8fVXdvMHzDMIWZhCWz2sZJI3Gqx3dQpibWwjL5xaCpNEYBEnNIEhqq2MPsFnugy7f+eefP9haR48eHWSd1dXhvoVPnDgx2FpDGfIYwjzcQpDUDIKkZhAkNYMgqRkESc0gSGoGQVIzCJKaQZDUDIKkZhAkNYMgqRkESc0gSGoGQVIzCJKaQZDUDIKktmVvw67lG/J7Zahbg11wwQWDrAPwxhtvDLbWFHkbdklnxSBIagZBUjMIkppBkNQWCkKSC5PsT/LTJAeTfHyowSQt36J/9ubrwPeq6i+TbAd2DDCTpJFsOghJdgF7gL8GqKpjwLFhxpI0hkV2GT4MvAR8M8lTSe5NsnOguSSNYJEgrAIfA75RVdcCR4G71z8pyd4kB5IcWOC1JC3BIkE4BByqqsdnH+9nLRD/T1Xtq6rdVbV7gdeStASbDkJV/QZ4IclHZg/dCDw7yFSSRrHobxm+ADww+w3Dc8DnFh9J0li82lFz82rHrc2rHSWdFYMgqRkESc0gSGpb9qDiueeeO8g6b7311iDrvB+cc85wPz9OnTo12FqajwcVJZ0VgyCpGQRJzSBIagZBUjMIkppBkNQMgqRmECQ1gyCpGQRJzSBIagZBUjMIkppBkNQMgqRmECS1Rf8uw2iOHz8+9gjvO9u2bRtsraHuVLVnz55B1gF47LHHBltrq3ILQVIzCJKaQZDUDIKkZhAktYWCkORLSZ5J8nSSB5OcN9RgkpZv00FIchnwRWB3VX0UWAE+O9RgkpZv0V2GVeD8JKvADuDXi48kaSybDkJV/Qr4CvA8cBj4bVX9YKjBJC3fIrsMFwG3AFcBHwJ2JrntbZ63N8mBJAc2P6akZVhkl+FTwC+q6qWqOg48BHxi/ZOqal9V7a6q3Qu8lqQlWCQIzwPXJdmRJMCNwMFhxpI0hkWOITwO7AeeBH4yW2vfQHNJGsFCVztW1T3APQPNImlknqkoqRkESc0gSGoGQVJLVS3vxZLlvZgGt/bb5WEs8/tOa6pqwy+gWwiSmkGQ1AyCpGYQJDWDIKkZBEnNIEhqBkFSMwiSmkGQ1AyCpGYQJDWDIKkZBEnNIEhqBkFSMwiSmkGQ1Bb6uwx6f5nibc+8rduw3EKQ1AyCpGYQJDWDIKkZBEltwyAkuS/JkSRPn/HYxUl+mORns7cXvbtjSlqGebYQvgXctO6xu4FHq+pq4NHZx5K2uA2DUFWPAa+se/gW4P7Z+/cDtw48l6QRbPbEpA9W1WGAqjqc5APv9MQke4G9m3wdSUv0rp+pWFX7gH3gH3uVpm6zv2V4McmlALO3R4YbSdJYNhuEh4E7Zu/fAXx3mHEkjSkbXdCR5EHgBuAS4EXgHuA/gG8DfwA8D3ymqtYfeHy7tdxl0KC8uGl+VbXhJ2vDIAzJIGhoBmF+8wTBMxUlNYMgqRkESW3L3jFp165dg6zz2muvDbIOwMrKymBrnTx5crC1hnLhhRcOttarr7462FrvZUN9zl9//fW5nucWgqRmECQ1gyCpGQRJzSBIagZBUjMIkppBkNQMgqRmECQ1gyCpGQRJzSBIagZBUjMIkppBkNQMgqRmECS1Zd+G/SXglxs87RLg5SWMczamOBNMcy5nms+yZ/rDqvr9jZ601CDMI8mBqto99hxnmuJMMM25nGk+U5wJ3GWQdAaDIKlNMQj7xh7gbUxxJpjmXM40nynONL1jCJLGM8UtBEkjMQiSmkGQ1AyCpGYQJLX/A3gSNpq1F+bnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mx = confusion_matrix(y_valid_indices, y_pred_indices)\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   0,   0,   0,   0,   7,   0,   1,   0,   0,   1],\n",
       "       [  0,  48,   0,   2,   0,   0,   0,   0,   2,   0,   0,  13],\n",
       "       [  0,   2,   1,   0,   0,   0,   3,   0,   0,   0,   0,   0],\n",
       "       [  0,   4,   0,   1,   0,   0,  23,   0,   1,   0,   0,   7],\n",
       "       [  0,   4,   0,   0,   0,   0,   3,   0,   0,   0,   0,   2],\n",
       "       [  0,   2,   0,   0,   0,   0,  13,   0,   5,   0,   0,   3],\n",
       "       [  0,   1,   0,   0,   0,   0, 291,   0,  14,   0,   0,   1],\n",
       "       [  0,   8,   0,   0,   0,   0,   3,   0,   0,   0,   0,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   9,   0,  71,   0,   0,   0],\n",
       "       [  0,   1,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0],\n",
       "       [  0,   1,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0],\n",
       "       [  0,  16,   0,   4,   0,   0,  19,   1,   2,   0,   0,  19]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 3496 samples, validate on 617 samples\n",
      "Epoch 1/50\n",
      "3496/3496 [==============================] - 739s 211ms/step - loss: 1.7221 - accuracy: 0.4886 - val_loss: 1.6576 - val_accuracy: 0.4976\n",
      "\n",
      "Epoch 00001: saving model to models/2/weights.01-1.66.hdf5\n",
      "Epoch 2/50\n",
      "3496/3496 [==============================] - 724s 207ms/step - loss: 1.6475 - accuracy: 0.4951 - val_loss: 1.6392 - val_accuracy: 0.5008\n",
      "\n",
      "Epoch 00002: saving model to models/2/weights.02-1.64.hdf5\n",
      "Epoch 3/50\n",
      "3496/3496 [==============================] - 725s 207ms/step - loss: 1.6820 - accuracy: 0.4937 - val_loss: 1.7100 - val_accuracy: 0.4976\n",
      "\n",
      "Epoch 00003: saving model to models/2/weights.03-1.71.hdf5\n",
      "Epoch 4/50\n",
      "3496/3496 [==============================] - 735s 210ms/step - loss: 1.6716 - accuracy: 0.4980 - val_loss: 1.6569 - val_accuracy: 0.4976\n",
      "\n",
      "Epoch 00004: saving model to models/2/weights.04-1.66.hdf5\n",
      "Epoch 5/50\n",
      "3496/3496 [==============================] - 730s 209ms/step - loss: 1.6425 - accuracy: 0.4980 - val_loss: 1.7284 - val_accuracy: 0.4554\n",
      "\n",
      "Epoch 00005: saving model to models/2/weights.05-1.73.hdf5\n",
      "Epoch 6/50\n",
      "3496/3496 [==============================] - 726s 208ms/step - loss: 1.5981 - accuracy: 0.5029 - val_loss: 1.5826 - val_accuracy: 0.5348\n",
      "\n",
      "Epoch 00006: saving model to models/2/weights.06-1.58.hdf5\n",
      "Epoch 7/50\n",
      "3496/3496 [==============================] - 730s 209ms/step - loss: 1.5672 - accuracy: 0.5117 - val_loss: 1.5614 - val_accuracy: 0.5316\n",
      "\n",
      "Epoch 00007: saving model to models/2/weights.07-1.56.hdf5\n",
      "Epoch 8/50\n",
      "3496/3496 [==============================] - 745s 213ms/step - loss: 1.4843 - accuracy: 0.5452 - val_loss: 1.4346 - val_accuracy: 0.5478\n",
      "\n",
      "Epoch 00008: saving model to models/2/weights.08-1.43.hdf5\n",
      "Epoch 9/50\n",
      "3496/3496 [==============================] - 723s 207ms/step - loss: 1.3805 - accuracy: 0.5818 - val_loss: 1.2856 - val_accuracy: 0.6418\n",
      "\n",
      "Epoch 00009: saving model to models/2/weights.09-1.29.hdf5\n",
      "Epoch 10/50\n",
      "3496/3496 [==============================] - 751s 215ms/step - loss: 1.3373 - accuracy: 0.6038 - val_loss: 1.2363 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00010: saving model to models/2/weights.10-1.24.hdf5\n",
      "Epoch 11/50\n",
      "3496/3496 [==============================] - 796s 228ms/step - loss: 1.2701 - accuracy: 0.6239 - val_loss: 1.1838 - val_accuracy: 0.6677\n",
      "\n",
      "Epoch 00011: saving model to models/2/weights.11-1.18.hdf5\n",
      "Epoch 12/50\n",
      "3496/3496 [==============================] - 748s 214ms/step - loss: 1.2297 - accuracy: 0.6459 - val_loss: 1.2741 - val_accuracy: 0.6532\n",
      "\n",
      "Epoch 00012: saving model to models/2/weights.12-1.27.hdf5\n",
      "Epoch 13/50\n",
      "3496/3496 [==============================] - 748s 214ms/step - loss: 1.2857 - accuracy: 0.6196 - val_loss: 1.1940 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00013: saving model to models/2/weights.13-1.19.hdf5\n",
      "Epoch 14/50\n",
      "3496/3496 [==============================] - 760s 217ms/step - loss: 1.1827 - accuracy: 0.6590 - val_loss: 1.1855 - val_accuracy: 0.6888\n",
      "\n",
      "Epoch 00014: saving model to models/2/weights.14-1.19.hdf5\n",
      "Epoch 15/50\n",
      "3496/3496 [==============================] - 768s 220ms/step - loss: 1.1479 - accuracy: 0.6685 - val_loss: 1.1571 - val_accuracy: 0.6872\n",
      "\n",
      "Epoch 00015: saving model to models/2/weights.15-1.16.hdf5\n",
      "Epoch 16/50\n",
      "3496/3496 [==============================] - 766s 219ms/step - loss: 1.1400 - accuracy: 0.6702 - val_loss: 1.1275 - val_accuracy: 0.6856\n",
      "\n",
      "Epoch 00016: saving model to models/2/weights.16-1.13.hdf5\n",
      "Epoch 17/50\n",
      "3496/3496 [==============================] - 731s 209ms/step - loss: 1.1068 - accuracy: 0.6753 - val_loss: 1.1377 - val_accuracy: 0.6888\n",
      "\n",
      "Epoch 00017: saving model to models/2/weights.17-1.14.hdf5\n",
      "Epoch 18/50\n",
      "3496/3496 [==============================] - 749s 214ms/step - loss: 1.0839 - accuracy: 0.6856 - val_loss: 1.1288 - val_accuracy: 0.6921\n",
      "\n",
      "Epoch 00018: saving model to models/2/weights.18-1.13.hdf5\n",
      "Epoch 19/50\n",
      "3496/3496 [==============================] - 787s 225ms/step - loss: 1.0655 - accuracy: 0.6908 - val_loss: 1.1777 - val_accuracy: 0.6840\n",
      "\n",
      "Epoch 00019: saving model to models/2/weights.19-1.18.hdf5\n",
      "Epoch 20/50\n",
      "3496/3496 [==============================] - 765s 219ms/step - loss: 1.0446 - accuracy: 0.6971 - val_loss: 1.0996 - val_accuracy: 0.7002\n",
      "\n",
      "Epoch 00020: saving model to models/2/weights.20-1.10.hdf5\n",
      "Epoch 21/50\n",
      "3496/3496 [==============================] - 774s 221ms/step - loss: 1.0243 - accuracy: 0.7057 - val_loss: 1.1200 - val_accuracy: 0.6937\n",
      "\n",
      "Epoch 00021: saving model to models/2/weights.21-1.12.hdf5\n",
      "Epoch 22/50\n",
      "3496/3496 [==============================] - 906s 259ms/step - loss: 1.0009 - accuracy: 0.7057 - val_loss: 1.1233 - val_accuracy: 0.6872\n",
      "\n",
      "Epoch 00022: saving model to models/2/weights.22-1.12.hdf5\n",
      "Epoch 23/50\n",
      "3496/3496 [==============================] - 987s 282ms/step - loss: 0.9684 - accuracy: 0.7108 - val_loss: 1.1165 - val_accuracy: 0.7002\n",
      "\n",
      "Epoch 00023: saving model to models/2/weights.23-1.12.hdf5\n",
      "Epoch 24/50\n",
      "3496/3496 [==============================] - 855s 245ms/step - loss: 0.9600 - accuracy: 0.7200 - val_loss: 1.1083 - val_accuracy: 0.6937\n",
      "\n",
      "Epoch 00024: saving model to models/2/weights.24-1.11.hdf5\n",
      "Epoch 25/50\n",
      "3496/3496 [==============================] - 769s 220ms/step - loss: 0.9325 - accuracy: 0.7223 - val_loss: 1.1441 - val_accuracy: 0.7018\n",
      "\n",
      "Epoch 00025: saving model to models/2/weights.25-1.14.hdf5\n",
      "Epoch 26/50\n",
      "3496/3496 [==============================] - 802s 229ms/step - loss: 0.9090 - accuracy: 0.7311 - val_loss: 1.1156 - val_accuracy: 0.6937\n",
      "\n",
      "Epoch 00026: saving model to models/2/weights.26-1.12.hdf5\n",
      "Epoch 27/50\n",
      "3496/3496 [==============================] - 738s 211ms/step - loss: 0.8766 - accuracy: 0.7383 - val_loss: 1.1380 - val_accuracy: 0.7050\n",
      "\n",
      "Epoch 00027: saving model to models/2/weights.27-1.14.hdf5\n",
      "Epoch 28/50\n",
      "3496/3496 [==============================] - 771s 221ms/step - loss: 0.8496 - accuracy: 0.7440 - val_loss: 1.1622 - val_accuracy: 0.6921\n",
      "\n",
      "Epoch 00028: saving model to models/2/weights.28-1.16.hdf5\n",
      "Epoch 29/50\n",
      "3496/3496 [==============================] - 737s 211ms/step - loss: 0.8072 - accuracy: 0.7491 - val_loss: 1.1366 - val_accuracy: 0.7002\n",
      "\n",
      "Epoch 00029: saving model to models/2/weights.29-1.14.hdf5\n",
      "Epoch 30/50\n",
      "3496/3496 [==============================] - 728s 208ms/step - loss: 0.7814 - accuracy: 0.7580 - val_loss: 1.1584 - val_accuracy: 0.6807\n",
      "\n",
      "Epoch 00030: saving model to models/2/weights.30-1.16.hdf5\n",
      "Epoch 31/50\n",
      "3496/3496 [==============================] - 724s 207ms/step - loss: 0.7546 - accuracy: 0.7649 - val_loss: 1.1716 - val_accuracy: 0.6888\n",
      "\n",
      "Epoch 00031: saving model to models/2/weights.31-1.17.hdf5\n",
      "Epoch 32/50\n",
      "3496/3496 [==============================] - 729s 209ms/step - loss: 0.7093 - accuracy: 0.7809 - val_loss: 1.2065 - val_accuracy: 0.6807\n",
      "\n",
      "Epoch 00032: saving model to models/2/weights.32-1.21.hdf5\n",
      "Epoch 33/50\n",
      "3496/3496 [==============================] - 722s 207ms/step - loss: 0.6772 - accuracy: 0.7849 - val_loss: 1.2405 - val_accuracy: 0.6872\n",
      "\n",
      "Epoch 00033: saving model to models/2/weights.33-1.24.hdf5\n",
      "Epoch 34/50\n",
      "3496/3496 [==============================] - 723s 207ms/step - loss: 0.6222 - accuracy: 0.8046 - val_loss: 1.2678 - val_accuracy: 0.6759\n",
      "\n",
      "Epoch 00034: saving model to models/2/weights.34-1.27.hdf5\n",
      "Epoch 35/50\n",
      "3496/3496 [==============================] - 727s 208ms/step - loss: 0.6046 - accuracy: 0.8023 - val_loss: 1.2492 - val_accuracy: 0.6726\n",
      "\n",
      "Epoch 00035: saving model to models/2/weights.35-1.25.hdf5\n",
      "Epoch 36/50\n",
      "3496/3496 [==============================] - 722s 206ms/step - loss: 0.5314 - accuracy: 0.8264 - val_loss: 1.3024 - val_accuracy: 0.6629\n",
      "\n",
      "Epoch 00036: saving model to models/2/weights.36-1.30.hdf5\n",
      "Epoch 37/50\n",
      "3496/3496 [==============================] - 724s 207ms/step - loss: 0.5035 - accuracy: 0.8332 - val_loss: 1.3077 - val_accuracy: 0.6872\n",
      "\n",
      "Epoch 00037: saving model to models/2/weights.37-1.31.hdf5\n",
      "Epoch 38/50\n",
      "3496/3496 [==============================] - 724s 207ms/step - loss: 0.4654 - accuracy: 0.8504 - val_loss: 1.3474 - val_accuracy: 0.6856\n",
      "\n",
      "Epoch 00038: saving model to models/2/weights.38-1.35.hdf5\n",
      "Epoch 39/50\n",
      "3496/3496 [==============================] - 722s 207ms/step - loss: 0.4183 - accuracy: 0.8644 - val_loss: 1.3691 - val_accuracy: 0.6807\n",
      "\n",
      "Epoch 00039: saving model to models/2/weights.39-1.37.hdf5\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3496/3496 [==============================] - 728s 208ms/step - loss: 0.3845 - accuracy: 0.8796 - val_loss: 1.4231 - val_accuracy: 0.6840\n",
      "\n",
      "Epoch 00040: saving model to models/2/weights.40-1.42.hdf5\n",
      "Epoch 41/50\n",
      "3496/3496 [==============================] - 723s 207ms/step - loss: 0.3693 - accuracy: 0.8830 - val_loss: 1.4354 - val_accuracy: 0.6710\n",
      "\n",
      "Epoch 00041: saving model to models/2/weights.41-1.44.hdf5\n",
      "Epoch 42/50\n",
      "3496/3496 [==============================] - 721s 206ms/step - loss: 0.3199 - accuracy: 0.8962 - val_loss: 1.5442 - val_accuracy: 0.6613\n",
      "\n",
      "Epoch 00042: saving model to models/2/weights.42-1.54.hdf5\n",
      "Epoch 43/50\n",
      "3496/3496 [==============================] - 722s 206ms/step - loss: 0.2961 - accuracy: 0.9082 - val_loss: 1.5586 - val_accuracy: 0.6807\n",
      "\n",
      "Epoch 00043: saving model to models/2/weights.43-1.56.hdf5\n",
      "Epoch 44/50\n",
      "3496/3496 [==============================] - 721s 206ms/step - loss: 0.2752 - accuracy: 0.9191 - val_loss: 1.5449 - val_accuracy: 0.6580\n",
      "\n",
      "Epoch 00044: saving model to models/2/weights.44-1.54.hdf5\n",
      "Epoch 45/50\n",
      "3496/3496 [==============================] - 725s 207ms/step - loss: 0.2573 - accuracy: 0.9193 - val_loss: 1.5702 - val_accuracy: 0.6467\n",
      "\n",
      "Epoch 00045: saving model to models/2/weights.45-1.57.hdf5\n",
      "Epoch 46/50\n",
      "3496/3496 [==============================] - 721s 206ms/step - loss: 0.2451 - accuracy: 0.9205 - val_loss: 1.6244 - val_accuracy: 0.6467\n",
      "\n",
      "Epoch 00046: saving model to models/2/weights.46-1.62.hdf5\n",
      "Epoch 47/50\n",
      "3496/3496 [==============================] - 723s 207ms/step - loss: 0.2314 - accuracy: 0.9296 - val_loss: 1.6405 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00047: saving model to models/2/weights.47-1.64.hdf5\n",
      "Epoch 48/50\n",
      "3496/3496 [==============================] - 722s 207ms/step - loss: 0.2102 - accuracy: 0.9371 - val_loss: 1.6316 - val_accuracy: 0.6596\n",
      "\n",
      "Epoch 00048: saving model to models/2/weights.48-1.63.hdf5\n",
      "Epoch 49/50\n",
      "3496/3496 [==============================] - 722s 206ms/step - loss: 0.1886 - accuracy: 0.9425 - val_loss: 1.6678 - val_accuracy: 0.6791\n",
      "\n",
      "Epoch 00049: saving model to models/2/weights.49-1.67.hdf5\n",
      "Epoch 50/50\n",
      "3496/3496 [==============================] - 728s 208ms/step - loss: 0.1821 - accuracy: 0.9474 - val_loss: 1.6953 - val_accuracy: 0.6645\n",
      "\n",
      "Epoch 00050: saving model to models/2/weights.50-1.70.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f3351e01d68>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 192, input_length=max_len))\n",
    "model.add(Bidirectional(LSTM(192, dropout = 0.2, recurrent_dropout= 0.2)))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile('Nadam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='models/2/weights.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only=False)\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train_pad, y_train_OH,\n",
    "          batch_size=batch_size,\n",
    "          epochs=50, class_weight= class_weights,            \n",
    "          validation_data=[x_valid_pad, y_valid_OH],\n",
    "          callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1501, 192)         384000    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 384)               591360    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                4620      \n",
      "=================================================================\n",
      "Total params: 979,980\n",
      "Trainable params: 979,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "best_model = load_model('models/2/weights.22-1.12.hdf5')\n",
    "# summarize model.\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(x_valid_pad)\n",
    "y_pred_indices = OH_to_label_indices(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mx = confusion_matrix(y_valid_indices, y_pred_indices)\n",
    "plt.matshow(conf_mx / (conf_mx.max(axis=0)+1), cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 192, input_length=max_len))\n",
    "model.add(Bidirectional(\n",
    "    LSTM(192, \n",
    "         dropout = 0.2, \n",
    "         recurrent_dropout= 0.2#, \n",
    "         #kernel_regularizer=regularizers.l2(0.01),\n",
    "        )))\n",
    "model.add(LSTM(64, dropout = 0.2, recurrent_dropout= 0.2))\n",
    "model.add(Dense(12, activation='softmax'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
