{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "import tempfile, sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import deepexplain\n",
    "#from deepexplain.tensorflow import DeepExplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/3Classes_train.csv\", sep=\"\\t\")\n",
    "valid = pd.read_csv(\"data/3Classes_valid.csv\", sep=\"\\t\")\n",
    "\n",
    "y_train = train[\"Global classifier2\"]\n",
    "y_valid = valid[\"Global classifier2\"]\n",
    "\n",
    "x_train = train[\"Sequence\"].copy()\n",
    "x_valid = valid[\"Sequence\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4015 train sequences\n",
      "709 test sequences\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_valid), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_adder(X):\n",
    "    for s in range(len(X)):\n",
    "        X.loc[s] += '*'\n",
    "    return X\n",
    "\n",
    "x_train = end_adder(x_train)\n",
    "x_valid = end_adder(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501\n"
     ]
    }
   ],
   "source": [
    "max_len = len(max(x_train, key=len))\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all amino acids (in blosum order)\n",
    "aa = \"ARNDCQEGHILKMFPSTWYVU*\"\n",
    "tot_aa = len(aa)\n",
    "\n",
    "# define a mapping of aa to integers\n",
    "aa_to_int = dict((c, i) for i, c in enumerate(aa))\n",
    "int_to_aa = dict((i, c) for i, c in enumerate(aa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['Mostly Cytosolic', 'Mostly Nuclear', 'Mostly Organellar']\n",
    "\n",
    "tot_cat = len(cat)\n",
    "cat_to_int = {}\n",
    "int_to_cat = {}\n",
    "for i in range(tot_cat):\n",
    "    cat_to_int[cat[i]] = i\n",
    "    int_to_cat[i] = cat[i]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_indices(Y):\n",
    "    Y_indices = np.zeros([Y.shape[0],], dtype=int)\n",
    "    for i in range(len(Y)):\n",
    "        Y_indices[i] = cat_to_int[Y[i]]\n",
    "    return Y_indices\n",
    "\n",
    "# one hot encode\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_indices = cat_to_indices(y_train)\n",
    "y_valid_indices = cat_to_indices(y_valid)\n",
    "\n",
    "y_train_OH = convert_to_one_hot(y_train_indices, C = tot_cat)\n",
    "y_valid_OH = convert_to_one_hot(y_valid_indices, C = tot_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_train processing: \n",
    "### From Sequences to list of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert sequences to array of indices. I will that that one for embedding \n",
    "\n",
    "def seq_to_indices(X, aa_to_int, max_len):\n",
    "    \n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (â‰ˆ 1 line)\n",
    "    X_indices = []\n",
    "    \n",
    "    for i in range(m):                               # loop over training examples\n",
    "        seq_aa = X[i]\n",
    "        seq_ind = []\n",
    "        \n",
    "        # Loop over the words of sentence_words\n",
    "        for w in range(len(seq_aa)):\n",
    "            seq_ind.append(aa_to_int[seq_aa[w]])\n",
    "            \n",
    "        X_indices.append(seq_ind)\n",
    "            \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_indices = seq_to_indices(x_train, aa_to_int, max_len)\n",
    "x_valid_indices = seq_to_indices(x_valid, aa_to_int, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (4015, 1501)\n",
      "x_valid shape: (709, 1501)\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences\n",
    "# By default, the padding is added before the sequence\n",
    "x_train_pad = sequence.pad_sequences(x_train_indices, maxlen=max_len, value=aa_to_int[\"*\"])\n",
    "x_valid_pad = sequence.pad_sequences(x_valid_indices, maxlen=max_len, value=aa_to_int[\"*\"])\n",
    "print('x_train shape:', x_train_pad.shape)\n",
    "print('x_valid shape:', x_valid_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot to label \n",
    "#Y is list of OH vector\n",
    "def OH_to_label_indices(Y):\n",
    "    labels = []\n",
    "    for a in Y:\n",
    "        indices = np.argmax(a)\n",
    "        labels.append(indices)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_cat(Y):\n",
    "    Y_cat = []\n",
    "    for i in range(len(Y)):\n",
    "        Y_cat.append(int_to_cat[Y[i]])\n",
    "    return Y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 2000\n",
    "# cut texts after this number of words\n",
    "\n",
    "# It's apparently important to Optimize batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 4446 samples, validate on 1112 samples\n",
      "Epoch 1/10\n",
      "4446/4446 [==============================] - 602s 135ms/step - loss: 0.9879 - accuracy: 0.5162 - val_loss: 0.9287 - val_accuracy: 0.5638\n",
      "Epoch 2/10\n",
      "4446/4446 [==============================] - 602s 135ms/step - loss: 0.9033 - accuracy: 0.5661 - val_loss: 0.8672 - val_accuracy: 0.6115\n",
      "Epoch 3/10\n",
      "4446/4446 [==============================] - 593s 133ms/step - loss: 0.8346 - accuracy: 0.6199 - val_loss: 0.7958 - val_accuracy: 0.6394\n",
      "Epoch 4/10\n",
      "4446/4446 [==============================] - 587s 132ms/step - loss: 0.8319 - accuracy: 0.6257 - val_loss: 0.7762 - val_accuracy: 0.6304\n",
      "Epoch 5/10\n",
      "4446/4446 [==============================] - 584s 131ms/step - loss: 0.7649 - accuracy: 0.6480 - val_loss: 0.7237 - val_accuracy: 0.6673\n",
      "Epoch 6/10\n",
      "4446/4446 [==============================] - 589s 133ms/step - loss: 0.7975 - accuracy: 0.6300 - val_loss: 0.8715 - val_accuracy: 0.5953\n",
      "Epoch 7/10\n",
      "4446/4446 [==============================] - 588s 132ms/step - loss: 0.7714 - accuracy: 0.6561 - val_loss: 0.7516 - val_accuracy: 0.6412\n",
      "Epoch 8/10\n",
      "4446/4446 [==============================] - 589s 132ms/step - loss: 0.7354 - accuracy: 0.6655 - val_loss: 0.7406 - val_accuracy: 0.6583\n",
      "Epoch 9/10\n",
      "4446/4446 [==============================] - 667s 150ms/step - loss: 0.7147 - accuracy: 0.6838 - val_loss: 0.7176 - val_accuracy: 0.6835\n",
      "Epoch 10/10\n",
      "4446/4446 [==============================] - 584s 131ms/step - loss: 0.6911 - accuracy: 0.7000 - val_loss: 0.7055 - val_accuracy: 0.6835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f3dbd859be0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 192, input_length=max_len))\n",
    "model.add(Bidirectional(LSTM(192)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile('Nadam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='models/weights.{epoch:02d}-{val_loss:.2f}.hdf5', \n",
    "                               verbose=1, save_best_only=False)\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train_pad, y_train_OH,\n",
    "          batch_size=batch_size,\n",
    "          epochs=25, \n",
    "          class_weight= class_weights\n",
    "          validation_data=[x_valid_pad, y_valid_OH],\n",
    "          callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01793272, 0.0089309 , 0.9731364 ],\n",
       "       [0.00866692, 0.00539388, 0.98593915],\n",
       "       [0.5470672 , 0.17994563, 0.27298716],\n",
       "       ...,\n",
       "       [0.5351773 , 0.28138697, 0.18343566],\n",
       "       [0.00954634, 0.00613804, 0.9843156 ],\n",
       "       [0.01238737, 0.00806033, 0.9795523 ]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_valid_indices)\n",
    "y_pred_indices = OH_to_label_indices(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[313,  21,  50],\n",
       "       [144,  37,  20],\n",
       "       [102,  15, 410]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mx = confusion_matrix(y_valid_pad, y_pred_indices)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1501, 192)         384000    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 384)               591360    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1155      \n",
      "=================================================================\n",
      "Total params: 976,515\n",
      "Trainable params: 976,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "best_model = load_model('models/weights.hdf5')\n",
    "# summarize model.\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "y_pred = best_model.predict(x_valid_pad)\n",
    "y_pred_indices = OH_to_label_indices(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mx = confusion_matrix(y_valid_pad, y_pred_indices)\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 4015 samples, validate on 709 samples\n",
      "Epoch 1/25\n",
      "4015/4015 [==============================] - 466s 116ms/step - loss: 0.9489 - accuracy: 0.5534 - val_loss: 0.8763 - val_accuracy: 0.5755\n",
      "\n",
      "Epoch 00001: saving model to models/weights.01-0.88.hdf5\n",
      "Epoch 2/25\n",
      "4015/4015 [==============================] - 476s 119ms/step - loss: 0.9290 - accuracy: 0.5507 - val_loss: 0.8975 - val_accuracy: 0.5698\n",
      "\n",
      "Epoch 00002: saving model to models/weights.02-0.90.hdf5\n",
      "Epoch 3/25\n",
      "4015/4015 [==============================] - 461s 115ms/step - loss: 0.8931 - accuracy: 0.5626 - val_loss: 0.8911 - val_accuracy: 0.6008\n",
      "\n",
      "Epoch 00003: saving model to models/weights.03-0.89.hdf5\n",
      "Epoch 4/25\n",
      "4015/4015 [==============================] - 460s 115ms/step - loss: 0.8529 - accuracy: 0.5895 - val_loss: 0.8218 - val_accuracy: 0.6192\n",
      "\n",
      "Epoch 00004: saving model to models/weights.04-0.82.hdf5\n",
      "Epoch 5/25\n",
      "4015/4015 [==============================] - 460s 115ms/step - loss: 0.8522 - accuracy: 0.6037 - val_loss: 0.7832 - val_accuracy: 0.6305\n",
      "\n",
      "Epoch 00005: saving model to models/weights.05-0.78.hdf5\n",
      "Epoch 6/25\n",
      "4015/4015 [==============================] - 460s 115ms/step - loss: 0.7875 - accuracy: 0.6361 - val_loss: 0.7664 - val_accuracy: 0.6248\n",
      "\n",
      "Epoch 00006: saving model to models/weights.06-0.77.hdf5\n",
      "Epoch 7/25\n",
      "4015/4015 [==============================] - 502s 125ms/step - loss: 0.7544 - accuracy: 0.6526 - val_loss: 0.7341 - val_accuracy: 0.6587\n",
      "\n",
      "Epoch 00007: saving model to models/weights.07-0.73.hdf5\n",
      "Epoch 8/25\n",
      "4015/4015 [==============================] - 486s 121ms/step - loss: 0.7115 - accuracy: 0.6752 - val_loss: 0.7076 - val_accuracy: 0.6827\n",
      "\n",
      "Epoch 00008: saving model to models/weights.08-0.71.hdf5\n",
      "Epoch 9/25\n",
      "4015/4015 [==============================] - 513s 128ms/step - loss: 0.6637 - accuracy: 0.7113 - val_loss: 0.7157 - val_accuracy: 0.6869\n",
      "\n",
      "Epoch 00009: saving model to models/weights.09-0.72.hdf5\n",
      "Epoch 10/25\n",
      "4015/4015 [==============================] - 548s 137ms/step - loss: 0.6461 - accuracy: 0.7303 - val_loss: 0.6526 - val_accuracy: 0.7377\n",
      "\n",
      "Epoch 00010: saving model to models/weights.10-0.65.hdf5\n",
      "Epoch 11/25\n",
      "4015/4015 [==============================] - 560s 139ms/step - loss: 0.6209 - accuracy: 0.7572 - val_loss: 0.6292 - val_accuracy: 0.7433\n",
      "\n",
      "Epoch 00011: saving model to models/weights.11-0.63.hdf5\n",
      "Epoch 12/25\n",
      "4015/4015 [==============================] - 520s 130ms/step - loss: 0.5986 - accuracy: 0.7619 - val_loss: 0.6400 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00012: saving model to models/weights.12-0.64.hdf5\n",
      "Epoch 13/25\n",
      "4015/4015 [==============================] - 488s 122ms/step - loss: 0.5802 - accuracy: 0.7738 - val_loss: 0.6194 - val_accuracy: 0.7489\n",
      "\n",
      "Epoch 00013: saving model to models/weights.13-0.62.hdf5\n",
      "Epoch 14/25\n",
      "4015/4015 [==============================] - 511s 127ms/step - loss: 0.5659 - accuracy: 0.7781 - val_loss: 0.6189 - val_accuracy: 0.7532\n",
      "\n",
      "Epoch 00014: saving model to models/weights.14-0.62.hdf5\n",
      "Epoch 15/25\n",
      "4015/4015 [==============================] - 519s 129ms/step - loss: 0.5548 - accuracy: 0.7843 - val_loss: 0.6031 - val_accuracy: 0.7701\n",
      "\n",
      "Epoch 00015: saving model to models/weights.15-0.60.hdf5\n",
      "Epoch 16/25\n",
      "4015/4015 [==============================] - 561s 140ms/step - loss: 0.5472 - accuracy: 0.7933 - val_loss: 0.6657 - val_accuracy: 0.7405\n",
      "\n",
      "Epoch 00016: saving model to models/weights.16-0.67.hdf5\n",
      "Epoch 17/25\n",
      "4015/4015 [==============================] - 501s 125ms/step - loss: 0.5373 - accuracy: 0.7910 - val_loss: 0.5836 - val_accuracy: 0.7715\n",
      "\n",
      "Epoch 00017: saving model to models/weights.17-0.58.hdf5\n",
      "Epoch 18/25\n",
      "4015/4015 [==============================] - 564s 141ms/step - loss: 0.5301 - accuracy: 0.7975 - val_loss: 0.5868 - val_accuracy: 0.7729\n",
      "\n",
      "Epoch 00018: saving model to models/weights.18-0.59.hdf5\n",
      "Epoch 19/25\n",
      "4015/4015 [==============================] - 577s 144ms/step - loss: 0.5191 - accuracy: 0.8012 - val_loss: 0.5863 - val_accuracy: 0.7814\n",
      "\n",
      "Epoch 00019: saving model to models/weights.19-0.59.hdf5\n",
      "Epoch 20/25\n",
      "4015/4015 [==============================] - 514s 128ms/step - loss: 0.5075 - accuracy: 0.8107 - val_loss: 0.6045 - val_accuracy: 0.7602\n",
      "\n",
      "Epoch 00020: saving model to models/weights.20-0.60.hdf5\n",
      "Epoch 21/25\n",
      "4015/4015 [==============================] - 514s 128ms/step - loss: 0.4994 - accuracy: 0.8117 - val_loss: 0.5726 - val_accuracy: 0.7884\n",
      "\n",
      "Epoch 00021: saving model to models/weights.21-0.57.hdf5\n",
      "Epoch 22/25\n",
      "4015/4015 [==============================] - 624s 155ms/step - loss: 0.4914 - accuracy: 0.8132 - val_loss: 0.5884 - val_accuracy: 0.7814\n",
      "\n",
      "Epoch 00022: saving model to models/weights.22-0.59.hdf5\n",
      "Epoch 23/25\n",
      "4015/4015 [==============================] - 631s 157ms/step - loss: 0.4994 - accuracy: 0.8085 - val_loss: 0.5780 - val_accuracy: 0.7786\n",
      "\n",
      "Epoch 00023: saving model to models/weights.23-0.58.hdf5\n",
      "Epoch 24/25\n",
      "4015/4015 [==============================] - 513s 128ms/step - loss: 0.4737 - accuracy: 0.8214 - val_loss: 0.6020 - val_accuracy: 0.7602\n",
      "\n",
      "Epoch 00024: saving model to models/weights.24-0.60.hdf5\n",
      "Epoch 25/25\n",
      "4015/4015 [==============================] - 486s 121ms/step - loss: 0.4644 - accuracy: 0.8194 - val_loss: 0.5900 - val_accuracy: 0.7757\n",
      "\n",
      "Epoch 00025: saving model to models/weights.25-0.59.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff95c43b6a0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=max_len))\n",
    "model.add(Bidirectional(LSTM(128, dropout = 0.2, recurrent_dropout= 0.2)))\n",
    "model.add(Dense(64))\n",
    "# These two next lines need to be like that for DeepExplain\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax')) \n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile('Nadam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='models/2/weights.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only=False)\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train_pad, y_train_OH,\n",
    "          batch_size=batch_size,\n",
    "          epochs=40, class_weight= class_weights,            \n",
    "          validation_data=[x_test_pad, y_test_OH],\n",
    "          callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 1501, 128)         256000    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 527,491\n",
      "Trainable params: 527,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('models/weights.21-0.57.hdf5')\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "y_pred = best_model.predict(x_valid_pad)\n",
    "y_pred_indices = OH_to_label_indices(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mx = confusion_matrix(y_valid_pad, y_pred_indices)\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/3Classes_test.csv\", sep=\"\\t\")\n",
    "y_test = test[\"Global classifier2\"]\n",
    "y_test_indices = cat_to_indices(y_test)\n",
    "y_test_OH = convert_to_one_hot(y_test_indices, C = tot_cat)\n",
    "\n",
    "x_test = test[\"Sequence\"].copy()\n",
    "x_test = end_adder(x_test)\n",
    "x_test_indices = seq_to_indices(x_test, aa_to_int, max_len)\n",
    "x_test_pad = sequence.pad_sequences(x_test_indices, maxlen=max_len, value=aa_to_int[\"*\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test_pad, y_test_OH, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = best_model.predict(x_test_pad)\n",
    "test_pred_indices = OH_to_label_indices(y_pred)\n",
    "\n",
    "conf_mx = confusion_matrix(y_valid_pad, y_pred_indices)\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse what motifs the model picks up?\n",
    "\n",
    "### With DeepExplain\n",
    "\n",
    "https://github.com/marcoancona/DeepExplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with DeepExplain(session=K.get_session()) as de:  # <-- init DeepExplain context\n",
    "    # Need to reconstruct the graph in DeepExplain context, using the same weights.\n",
    "    # With Keras this is very easy:\n",
    "    # 1. Get the input tensor to the original model\n",
    "    input_tensor = model.layers[0].input\n",
    "    \n",
    "    # 2. We now target the output of the last dense layer (pre-softmax)\n",
    "    # To do so, create a new model sharing the same layers untill the last dense (index -2)\n",
    "    fModel = Model(inputs=input_tensor, outputs = model.layers[-2].output)\n",
    "    target_tensor = fModel(input_tensor)\n",
    "    \n",
    "    xs = x_valid_pad\n",
    "    ys = y_valid_OH\n",
    "    \n",
    "    attributions_gradin = de.explain('grad*input', target_tensor, input_tensor, xs, ys=ys, xs, ys=ys, batch_size=64)\n",
    "    #attributions_sal   = de.explain('saliency', target_tensor, input_tensor, xs, ys=ys)\n",
    "    #attributions_ig    = de.explain('intgrad', target_tensor, input_tensor, xs, ys=ys)\n",
    "    #attributions_occ   = de.explain('occlusion', target_tensor, input_tensor, xs, ys=ys)\n",
    "    \n",
    "    # Compare Gradient * Input with approximate Shapley Values\n",
    "    # Note1: Shapley Value sampling with 100 samples per feature (78400 runs) takes a couple of minutes on a GPU.\n",
    "    # Note2: 100 samples are not enough for convergence, the result might be affected by sampling variance\n",
    "    attributions_sv = de.explain('shapley_sampling', target_tensor, input_tensor, xs, ys=ys, samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeepExplain(session=current_session) as de:  # <-- init DeepExplain context\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 128, input_length=max_len))\n",
    "    model.add(Bidirectional(LSTM(128, dropout = 0.2, recurrent_dropout= 0.2)))\n",
    "    model.add(Dense(64))\n",
    "    # These two next lines need to be like that for DeepExplain\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax')) \n",
    "\n",
    "    # try using different optimizers and different optimizer configs\n",
    "    model.compile('Nadam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    checkpointer = ModelCheckpoint(filepath='models/2/weights.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only=False)\n",
    "\n",
    "    model.fit(x_train_pad, y_train_OH,\n",
    "          batch_size=batch_size,\n",
    "          epochs=40, class_weight= class_weights,            \n",
    "          validation_data=[x_test_pad, y_test_OH],\n",
    "          callbacks=[checkpointer])\n",
    "\n",
    "    # predict on test data\n",
    "    y_pred = model.predict(np.array(x_valid_pad))\n",
    "    \n",
    "    # Evaluate the embedding tensor on the model input (in other words, perform the lookup)\n",
    "    embedding_tensor = model.layers[0].output\n",
    "    input_tensor = model.inputs[0]\n",
    "    embedding_out = current_session.run(embedding_tensor, {input_tensor: X_test})\n",
    "\n",
    "    xs = x_valid_pad\n",
    "    ys = y_valid_OH\n",
    "    # Run DeepExplain with the embedding as input\n",
    "    attributions = de.explain('elrp', model.layers[-2].output * ys, model.layers[1].input, embedding_out);\n",
    "    print(\"attributions shape --- {}\".format(attributions.shape));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
