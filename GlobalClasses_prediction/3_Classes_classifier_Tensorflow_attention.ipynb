{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "#from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pylab import figure\n",
    "#import seaborn as sns\n",
    "#sns.set(style='white', context='poster', rc={'figure.figsize':(7,5)})\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import os \n",
    "import re \n",
    "\n",
    "import umap\n",
    "from keras import constraints\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import * # Keras is the most friendly Neural Network library, this Kernel use a lot of layers classes\n",
    "from keras.models import Model\n",
    "from keras import backend as K # The backend give us access to tensorflow operations and allow us to create the Attention class\n",
    "from keras import optimizers # Allow us to access the Adam class to modify some parameters\n",
    "from keras.callbacks import * # This object helps the model to train in a smarter way, avoiding overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/3Classes_train.csv\", sep=\"\\t\")\n",
    "valid = pd.read_csv(\"data/3Classes_valid.csv\", sep=\"\\t\")\n",
    "\n",
    "y_train = train[\"Global classifier2\"]\n",
    "y_valid = valid[\"Global classifier2\"]\n",
    "\n",
    "x_train = train[\"Sequence\"].copy()\n",
    "x_valid = valid[\"Sequence\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lead Protein ID</th>\n",
       "      <th>Global classifier2</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Sequence Lengh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q96MN5</td>\n",
       "      <td>Mostly Organellar</td>\n",
       "      <td>MDKFVIRTPRIQNSPQKKDSGGKVYKQATIESLKRVVVVEDIKRWK...</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P42575</td>\n",
       "      <td>Mostly Cytosolic</td>\n",
       "      <td>MAAPSAGSWSTFQHKELMAADRGRRILGVCGMHPHHQETLKKNRVV...</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q9NZP8</td>\n",
       "      <td>Mostly Organellar</td>\n",
       "      <td>MPGPRVWGKYLWRSPHSKGCPGAMWWLLLWGVLQACPTRGSVLLAQ...</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q96K80</td>\n",
       "      <td>Mostly Nuclear</td>\n",
       "      <td>MPDRDSYANGTGSSGGGPGGGGSEEASGAGVGSGGASSDAICRDFL...</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q86TA1</td>\n",
       "      <td>Mostly Cytosolic</td>\n",
       "      <td>MSIALKQVFNKDKTFRPKRKFEPGTQRFELHKRAQASLNSGVDLKA...</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Lead Protein ID Global classifier2  \\\n",
       "0          Q96MN5  Mostly Organellar   \n",
       "1          P42575   Mostly Cytosolic   \n",
       "2          Q9NZP8  Mostly Organellar   \n",
       "3          Q96K80     Mostly Nuclear   \n",
       "4          Q86TA1   Mostly Cytosolic   \n",
       "\n",
       "                                            Sequence  Sequence Lengh  \n",
       "0  MDKFVIRTPRIQNSPQKKDSGGKVYKQATIESLKRVVVVEDIKRWK...             208  \n",
       "1  MAAPSAGSWSTFQHKELMAADRGRRILGVCGMHPHHQETLKKNRVV...             452  \n",
       "2  MPGPRVWGKYLWRSPHSKGCPGAMWWLLLWGVLQACPTRGSVLLAQ...             487  \n",
       "3  MPDRDSYANGTGSSGGGPGGGGSEEASGAGVGSGGASSDAICRDFL...             434  \n",
       "4  MSIALKQVFNKDKTFRPKRKFEPGTQRFELHKRAQASLNSGVDLKA...             216  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4015 train sequences\n",
      "709 test sequences\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_valid), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = len(max(x_train, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all amino acids (in blosum order)\n",
    "aa = \"*ARNDCQEGHILKMFPSTWYVU\"\n",
    "tot_aa = len(aa)\n",
    "\n",
    "# define a mapping of aa to integers\n",
    "aa_to_int = dict((c, i) for i, c in enumerate(aa))\n",
    "int_to_aa = dict((i, c) for i, c in enumerate(aa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['Mostly Cytosolic', 'Mostly Nuclear', 'Mostly Organellar']\n",
    "\n",
    "tot_cat = len(cat)\n",
    "cat_to_int = {}\n",
    "int_to_cat = {}\n",
    "for i in range(tot_cat):\n",
    "    cat_to_int[cat[i]] = i\n",
    "    int_to_cat[i] = cat[i]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_indices(Y):\n",
    "    Y_indices = np.zeros([Y.shape[0],], dtype=int)\n",
    "    for i in range(len(Y)):\n",
    "        Y_indices[i] = cat_to_int[Y[i]]\n",
    "    return Y_indices\n",
    "\n",
    "# one hot encode\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_indices = cat_to_indices(y_train)\n",
    "y_valid_indices = cat_to_indices(y_valid)\n",
    "\n",
    "y_train_OH = convert_to_one_hot(y_train_indices, C = tot_cat)\n",
    "y_valid_OH = convert_to_one_hot(y_valid_indices, C = tot_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_train processing: \n",
    "### From Sequences to list of indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert sequences to array of indices. I will that that one for embedding \n",
    "\n",
    "def seq_to_indices(X, aa_to_int, max_len):\n",
    "    \n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (â‰ˆ 1 line)\n",
    "    X_indices = []\n",
    "    \n",
    "    for i in range(m):                               # loop over training examples\n",
    "        seq_aa = X[i]\n",
    "        seq_ind = []\n",
    "        \n",
    "        # Loop over the words of sentence_words\n",
    "        for w in range(len(seq_aa)):\n",
    "            seq_ind.append(aa_to_int[seq_aa[w]])\n",
    "            \n",
    "        X_indices.append(seq_ind)\n",
    "            \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_indices = seq_to_indices(x_train, aa_to_int, maxlen)\n",
    "x_valid_indices = seq_to_indices(x_valid, aa_to_int, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (4015, 1500)\n",
      "x_valid shape: (709, 1500)\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences\n",
    "# By default, the padding is added before the sequence\n",
    "x_train_pad = sequence.pad_sequences(x_train_indices, maxlen=maxlen, value=aa_to_int[\"*\"])\n",
    "x_valid_pad = sequence.pad_sequences(x_valid_indices, maxlen=maxlen, value=aa_to_int[\"*\"])\n",
    "print('x_train shape:', x_train_pad.shape)\n",
    "print('x_valid shape:', x_valid_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot to label \n",
    "#Y is list of OH vector\n",
    "def OH_to_label_indices(Y):\n",
    "    labels = []\n",
    "    for a in Y:\n",
    "        indices = np.argmax(a)\n",
    "        labels.append(indices)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_cat(Y):\n",
    "    Y_cat = []\n",
    "    for i in range(len(Y)):\n",
    "        Y_cat.append(int_to_cat[Y[i]])\n",
    "    return Y_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Model\n",
    "\n",
    "Attention from this source: https://mlwhiz.com/blog/2019/03/09/deeplearning_architectures_text_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(x, kernel):\n",
    "    \"\"\"\n",
    "    Wrapper for dot product operation, in order to be compatible with both\n",
    "    Theano and Tensorflow\n",
    "    Args:\n",
    "        x (): input\n",
    "        kernel (): weights\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    if K.backend() == 'tensorflow':\n",
    "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
    "    else:\n",
    "        return K.dot(x, kernel)\n",
    "    \n",
    "\n",
    "class AttentionWithContext(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.u_regularizer = regularizers.get(u_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.u_constraint = constraints.get(u_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(AttentionWithContext, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[-1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "\n",
    "        self.u = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_u'.format(self.name),\n",
    "                                 regularizer=self.u_regularizer,\n",
    "                                 constraint=self.u_constraint)\n",
    "\n",
    "        super(AttentionWithContext, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        uit = dot_product(x, self.W)\n",
    "\n",
    "        if self.bias:\n",
    "            uit += self.b\n",
    "\n",
    "        uit = K.tanh(uit)\n",
    "        ait = dot_product(uit, self.u)\n",
    "\n",
    "        a = K.exp(ait)\n",
    "\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number Îµ to the sum.\n",
    "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[-1]\n",
    "\n",
    "\n",
    "def model_lstm_atten(embedding_matrix):\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "    #x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "    x = AttentionWithContext()(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 80)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('models_attention/1/weights_embedding22.hdf5')\n",
    "embedding = model.get_layer('embedding_layer').get_weights()\n",
    "embedding = embedding[0]\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add_weight() got multiple values for argument 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-41c108ea5adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0md_class_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lstm_atten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m ckpt = ModelCheckpoint(filepath='models_tf_attention/weights_model1.hdf5', \n",
      "\u001b[0;32m<ipython-input-23-aa139323f38c>\u001b[0m in \u001b[0;36mmodel_lstm_atten\u001b[0;34m(embedding_matrix)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m#x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttentionWithContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sigmoid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-aa139323f38c>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     61\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{}_W'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                                  \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                                  constraint=self.W_constraint)\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             self.b = self.add_weight((input_shape[-1],),\n",
      "\u001b[0;31mTypeError\u001b[0m: add_weight() got multiple values for argument 'name'"
     ]
    }
   ],
   "source": [
    "max_features = tot_aa\n",
    "embed_size = 80\n",
    "units = 128\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "model = model_lstm_atten(embedding)\n",
    "\n",
    "ckpt = ModelCheckpoint(filepath='models_tf_attention/weights_model1.hdf5', \n",
    "                           verbose=1, save_best_only=True)\n",
    "# Train, train, train\n",
    "history = model.fit(x_train_pad, y_train_OH, \n",
    "                    batch_size=64, epochs=40,\n",
    "                    class_weight = class_weights,\n",
    "          validation_data=[x_valid_pad, y_valid_OH], callbacks=[ckpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = tot_aa\n",
    "embed_size = 40\n",
    "units = 128\n",
    "\n",
    "_input = Input(shape=[max_len], dtype='int32')\n",
    "\n",
    "# get the embedding layer\n",
    "embedded = Embedding(\n",
    "        input_dim=max_features,\n",
    "        output_dim=embed_size,\n",
    "        input_length=max_len,\n",
    "        name = 'embedding_layer',\n",
    "        trainable=True,\n",
    "        mask_zero=False\n",
    "    )(_input)\n",
    "\n",
    "lstm = Bidirectional(LSTM(units, return_sequences=True, \n",
    "                                 dropout=0.2, recurrent_dropout=0.2))(embedded)\n",
    "\n",
    "# compute importance for each step\n",
    "attention = AttentionWithContext()(lstm)\n",
    "\n",
    "dense = Dense(64, activation=\"relu\")(attention)\n",
    "\n",
    "probabilities = Dense(3, activation='softmax')(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models_attention/1/weights_embedding22.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file= 'models_attention/1/model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_valid_pad, y_valid_OH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_valid_pad)\n",
    "y_pred_indices = OH_to_label_indices(y_pred)\n",
    "y_pred_labels = indices_to_cat(y_pred_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_plot(y_valid, y_pred_labels, cat):\n",
    "    conf_mx = confusion_matrix(y_valid, y_pred_labels, labels=cat)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "    fig.colorbar(cax)\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(1))\n",
    "    ax.set_xticklabels([''] + cat,  rotation='vertical')\n",
    "    ax.set_yticklabels([''] + cat)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "confusion_plot(y_valid, y_pred_labels, cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_plot_norm(y_valid, y_pred_labels, cat, axis=1):\n",
    "    conf_mx = confusion_matrix(y_valid, y_pred_labels, labels=cat)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(conf_mx / (conf_mx.max(axis=axis)+1), cmap=plt.cm.gray)\n",
    "    fig.colorbar(cax)\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(1))\n",
    "    ax.set_xticklabels([''] + cat,  rotation='vertical')\n",
    "    ax.set_yticklabels([''] + cat)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    return(conf_mx)\n",
    "conf = confusion_plot_norm(y_valid, y_pred_labels, cat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_valid, y_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of the Embedding Layer\n",
    "\n",
    "Good article about different dimension reduction techniques:\n",
    "https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = model.get_layer('embedding_layer').get_weights()\n",
    "embedding = embedding[0]\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA plots of Embedding \n",
    "pca = PCA(n_components=2)\n",
    "embedding_pca = pca.fit_transform(embedding)\n",
    "print(\"original shape:   \", embedding.shape)\n",
    "print(\"transformed shape:\", embedding_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding(embedding, aa):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.scatter(embedding[:, 0], embedding[:, 1], edgecolor='none')\n",
    "    aaL = list(aa)\n",
    "    for i in range(len(aaL)):\n",
    "        ax.annotate(aaL[i], (embedding[:, 0][i], embedding[:, 1][i]))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding(embedding_pca, aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE plot\n",
    "\n",
    "t-distributed stochastic neighbor embedding\n",
    "\n",
    "Doc for tSNE: https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tSNE plots of Embedding \n",
    "tSNE = TSNE(n_components=2, perplexity=4)\n",
    "embedding_tSNE = tSNE.fit_transform(embedding)\n",
    "\n",
    "print(\"original shape:   \", embedding.shape)\n",
    "print(\"transformed shape:\", embedding_tSNE.shape)\n",
    "\n",
    "# NB: perplexity plays a huge role there, \n",
    "#since our number of feature is very small I should use a very small value (between 2 and 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding(embedding_tSNE, aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can distinguish 3 main group:\n",
    " - Negatively charged\n",
    " - Hydrophobic \n",
    " - Positively charged\n",
    "\n",
    "It would be nice to color them... \n",
    "Look how to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umap plot\n",
    "\n",
    "Umap documentation: https://umap-learn.readthedocs.io/en/latest/parameters.html\n",
    "\n",
    "n_neighbors is similar to perplexity for tSNE, important to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# umap plots of Embedding \n",
    "Umap = umap.UMAP(n_components=2, n_neighbors= 5)\n",
    "embedding_Umap = Umap.fit_transform(embedding)\n",
    "\n",
    "print(\"original shape:   \", embedding.shape)\n",
    "print(\"transformed shape:\", embedding_Umap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding(embedding_Umap, aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Umap3 = umap.UMAP(n_components=3, n_neighbors= 6)\n",
    "embedding_Umap3 = Umap3.fit_transform(embedding)\n",
    "\n",
    "print(\"original shape:   \", embedding.shape)\n",
    "print(\"transformed shape:\", embedding_Umap3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m= embedding_Umap3 # m is an array of (x,y,z) coordinate triplets\n",
    "\n",
    "fig = figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "aaL = list(aa)\n",
    "print(len(m))\n",
    "print(len(aaL))\n",
    "ax.scatter(m[:,0],m[:,1],m[:,2],color='b') \n",
    "for i in range(len(aaL)): #plot each point + it's index as text above\n",
    "    ax.text(m[i,0],m[i,1],m[i,2],  '%s' % (str(aaL[i])), size=10, zorder=1,  \n",
    "    color='k') \n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the attention layer\n",
    "\n",
    "I need some serious work on that one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=model.input,\n",
    "              outputs=[model.output, model.get_layer('attention_vect').output])\n",
    "outputs = model.predict(x_valid_pad)\n",
    "model_outputs = outputs[0]\n",
    "attention_outputs = outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_distrib = np.concatenate( attention_outputs, axis=0 )\n",
    "plt.hist(attention_distrib, normed=True, bins=50)\n",
    "plt.ylabel('Attention Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize attention values \n",
    "norm_attention = []\n",
    "for seq in attention_outputs:\n",
    "    norm_attention.append(seq / np.linalg.norm(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_distrib = np.concatenate( norm_attention, axis=0 )\n",
    "plt.hist(attention_distrib, normed=True, bins=50)\n",
    "plt.ylabel('Attention Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check attention for a single protein sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_to_seq(X):\n",
    "    seq = ''\n",
    "    for i in range(len(X)):\n",
    "        seq += int_to_aa[X[i]] \n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't fully understand that code\n",
    "# the color_charvals function doesn't work that well because my vector is big\n",
    "# and the values are very small, I need a better function\n",
    "\n",
    "class CharVal(object):\n",
    "    def __init__(self, char, val):\n",
    "        self.char = char\n",
    "        self.val = val\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.char\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#%02x%02x%02x' % rgb\n",
    "\n",
    "def color_charvals(s):\n",
    "    r = 0\n",
    "    if s.val < 0.07:\n",
    "        r = 255\n",
    "    elif s.val > 0.1:\n",
    "        r = 0\n",
    "    else:\n",
    "        r = 255*(1 - (s.val-0.07)/0.05)\n",
    "    r = int(r)\n",
    "    color = rgb_to_hex((255, r, 255))\n",
    "    return 'background-color: %s' % color\n",
    "    \n",
    "    #r = int(255/(s.val*10 +1))\n",
    "    #color = rgb_to_hex((r, r, r))\n",
    "    #return 'background-color: %s' % color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 6\n",
    "\n",
    "attention_output = attention_outputs[X][-max_len:]\n",
    "attention_seq = attention_output[1500-len(x_valid[X]):]\n",
    "attention = normalize(attention_seq[:,np.newaxis], axis=0).ravel()\n",
    "\n",
    "# match each aa and attention\n",
    "char_vals = [CharVal(c, v) for c, v in \n",
    "             zip(x_valid[X], attention)]\n",
    "\n",
    "char_df = pd.DataFrame(char_vals).transpose()\n",
    "# apply coloring values\n",
    "char_df = char_df.style.applymap(color_charvals)\n",
    "char_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_valid[X])\n",
    "print(valid['Lead Protein ID'][X])\n",
    "print(y_pred_labels[X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the 'nb_max' maximum attention weights values position through all proteins from the valid dataset and Visualisation\n",
    "\n",
    "Then, Compare motifs identified to this site: http://elm.eu.org/combined_search?query=NLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of highest values to select\n",
    "nb_max = 50\n",
    "max_att_indexes = []\n",
    "for seq in norm_attention:\n",
    "    max_att_indexes.append(np.sort(np.argpartition(seq, -nb_max)[-nb_max:]))\n",
    "max_att_nopad = []    \n",
    "for x in range(len(x_valid)):\n",
    "    max_att_nopad.append(max_att_indexes[x]-(1500-len(x_valid[x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 1\n",
    "\n",
    "def color_charvals(s):\n",
    "    r = 255-int(s.val*255)\n",
    "    color = rgb_to_hex((255,255 , r))\n",
    "    return 'background-color: %s' % color\n",
    "\n",
    "max_ind = max_att_nopad[X]\n",
    "max_vect = np.zeros(len(x_valid[X]))\n",
    "for val in max_ind:\n",
    "    max_vect[val] = 1\n",
    "# match each aa and attention\n",
    "char_vals = [CharVal(c, v) for c, v in \n",
    "             zip(x_valid[X], max_vect)]\n",
    "\n",
    "char_df = pd.DataFrame(char_vals).transpose()\n",
    "# apply coloring values\n",
    "char_df = char_df.style.applymap(color_charvals)\n",
    "char_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... Now I need to look for NLS in valid set and check whether attention catch all of them by comparing sequence indices from max attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get regions deemed important by the attention layer  into the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs_loc = []\n",
    "motifs = []\n",
    "stop = 0\n",
    "for l in max_att_nopad:\n",
    "    start = l[0]\n",
    "    for i in range(1,len(l)):\n",
    "        if l[i-1] + 3 >= l[i]:\n",
    "            stop = l[i]\n",
    "        else:\n",
    "            if start < stop:\n",
    "                motifs.append((start, stop))\n",
    "            start = l[i]\n",
    "    if start < stop:\n",
    "        motifs.append((start, stop))\n",
    "    motifs_loc.append(motifs)\n",
    "    motifs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs_aa = []\n",
    "motifs = []\n",
    "for i in range(len(motifs_loc)):\n",
    "    seq = x_valid[i]\n",
    "    m = motifs_loc[i]\n",
    "    for tup in m:\n",
    "        motifs.append(seq[tup[0]:tup[1]+1])\n",
    "    motifs_aa.append(motifs)\n",
    "    motifs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid[\"Model Prediction\"] = y_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid[\"Motifs\"] = motifs_aa\n",
    "valid[\"Motifs Localization\"] = motifs_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid['Motifs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of ELM Regex\n",
    "http://elm.eu.org/infos/help.html\n",
    "\n",
    "Regular expression usefull links:\n",
    "https://www.debuggex.com/cheatsheet/regex/python\n",
    "https://regex101.com/#python"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Consensus NLS motif: \n",
    "   K-K/R-X-K/R\n",
    "Classical motifs:     \n",
    "SV40 Large T-antigen: PKKKRKV\n",
    "NLS of nucleoplasmin: KR[PAATKKAGQA]KKKK\n",
    "EGL-13: MSRRRKANPTKLSENAKKLAKEVEN\n",
    "c-Myc: PAAKRVKLD\n",
    "TUS-protein: KLKIKRPVK\n",
    "\n",
    "Non classical ones? \n",
    "\n",
    "Bingo! X = 3 has one!!!\n",
    "\n",
    "This are the regular expression for known NLS motifs:\n",
    "[KR][KR].{7,15}[^DE]((K[RK])|(RK))(([^DE][KR])|([KR][^DE]))[^DE]\n",
    "[^DE]((K[RK])|(RK))[KRP][KR][^DE]\n",
    "[^DE]((K[RK])|(RK))(([^DE][KR])|([KR][^DE]))(([PKR])|([^DE][DE]))\n",
    "(([PKR].{0,1}[^DE])|([PKR]))((K[RK])|(RK))(([^DE][KR])|([KR][^DE]))[^DE]\n",
    "\n",
    "Nuclear exclusion sequence (NES):\n",
    "LxxxLxxLxL, LIMVF\n",
    "\n",
    "([DEQ].{0,1}[LIM].{2,3}[LIVMF][^P]{2,3}[LMVF].[LMIV].{0,3}[DE])|([DE].{0,1}[LIM].{2,3}[LIVMF][^P]{2,3}[LMVF].[LMIV].{0,3}[DEQ])\n",
    "\n",
    "How do I search for them? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Character\tName\tMeaning\n",
    ".\tdot\tAny amino acid allowed\n",
    "[...]\tcharacter class\tAmino acids listed are allowed\n",
    "[^...]\tnegated character class\tAmino acids listed are not allowed\n",
    "{ min, max }\tspecified range\tMin required, max allowed\n",
    "^\tcaret\tMatches the amino terminal\n",
    "$\tdollar\tMatches the carboxy terminal\n",
    "?\tquestion\tOne amino acid is allowed, but is optional\n",
    "*\tstar\tAny number of amino acids are allowed but are optional\n",
    "+\tplus\tOne amino acid is allowed, additional are optional\n",
    "|\talternation\tMatches either expression it separates\n",
    "(...)\tparentheses\t\n",
    "1. Used to mark positions of specific interest; e.g. the amino acid being covalently modified.\n",
    "2. Used to group parts of the expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLS_regex = ['[KR][KR].{7,15}[^DE]((K[RK])|(RK))(([^DE][KR])|([KR][^DE]))[^DE]',\n",
    "             '[^DE]((K[RK])|(RK))[KRP][KR][^DE]',\n",
    "             '[^DE]((K[RK])|(RK))(([^DE][KR])|([KR][^DE]))(([PKR])|([^DE][DE]))',\n",
    "             '(([PKR].{0,1}[^DE])|([PKR]))((K[RK])|(RK))(([^DE][KR])|([KR][^DE]))[^DE]']\n",
    "\n",
    "NES_regex = ['([DEQ].{0,1}[LIM].{2,3}[LIVMF][^P]{2,3}[LMVF].[LMIV].{0,3}[DE])|([DE].{0,1}[LIM].{2,3}[LIVMF][^P]{2,3}[LMVF].[LMIV].{0,3}[DEQ])']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLS_valid = []\n",
    "NLS_nb = 0 # count seq with NLS\n",
    "NLS_bool = []\n",
    "for seq in x_valid:\n",
    "    NLS = []\n",
    "    for motifs in NLS_regex:\n",
    "        match = re.finditer(motifs, seq)\n",
    "        if match:\n",
    "            for m in match:\n",
    "                NLS.append((m.start(), m.end()))\n",
    "    if NLS != []:\n",
    "        NLS_bool.append(True)\n",
    "        NLS.sort(key=lambda tup: tup[1])\n",
    "        NLS_nb +=1\n",
    "    else:\n",
    "        NLS_bool.append(False)\n",
    "    NLS_valid.append(NLS)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(NLS_nb/len(x_valid)*100) + '% of proteins in valid set have at least one NLS motifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid[\"NLS\"] = NLS_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid[\"NLS positions\"] = NLS_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isintersect(a, b):\n",
    "    for a0 in a:\n",
    "        for b0 in b:\n",
    "            if ((b0[0] <= a0[0] and a0[0] < b0[1]) or (a0[0] <= b0[0] and b0[0] < a0[1])):\n",
    "                return True\n",
    "    return False\n",
    "    #\n",
    "    #a0 = [(i[0], i[1], 0) for i in a]\n",
    "    #b0 = [(i[0], i[1], 1) for i in b]\n",
    "    #c = sorted(a0+b0, key=lambda i: i[0])\n",
    "    #for i in range(len(c)):\n",
    "    #    j = i+1\n",
    "    #    while j != len(c) and c[i][1] > c[j][0]:\n",
    "    #        if (c[i][2] != c[j][2]):\n",
    "    #            return True\n",
    "    #        j=j+1\n",
    "    #return False\n",
    "\n",
    "assert(isintersect([(0,10)], [(5, 15)])==True)\n",
    "assert(isintersect([(0,10)], [(10, 20)])==False)\n",
    "assert(isintersect([(0,10),(20,30)], [(10, 20), (30, 40)])==False)\n",
    "assert(isintersect([(0,10),(20,30)], [(10, 25), (30, 40)])==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLS_intersect = []\n",
    "for i in range(len(motifs_loc)):\n",
    "    NLS_intersect.append(isintersect(motifs_loc[i],NLS_valid[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid[\"NLS/Attention Intersect\"] = NLS_intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.groupby([\"Global classifier2\", \"NLS/Attention Intersect\"]).count()/valid.groupby(\"Global classifier2\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isintersect(motifs_loc[0],NLS_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nuclear = valid.loc[valid['Global classifier2'] == 'Mostly Nuclear']\n",
    "Nuclear.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.groupby([\"Global classifier2\", \"NLS\"]).count()/valid.groupby(\"Global classifier2\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same thing with NES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NES_valid = []\n",
    "NES_nb = 0 # count seq with NLS\n",
    "NES_bool = []\n",
    "for seq in x_valid:\n",
    "    NES = []\n",
    "    for motifs in NES_regex:\n",
    "        match = re.finditer(motifs, seq)\n",
    "        if match:\n",
    "            for m in match:\n",
    "                NES.append((m.start(), m.end()))\n",
    "    if NES != []:\n",
    "        NES_bool.append(True)\n",
    "        NES.sort(key=lambda tup: tup[1])\n",
    "        NES_nb +=1\n",
    "    else:\n",
    "        NES_bool.append(False)\n",
    "    NES_valid.append(NES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(NES_nb/len(x_valid)*100) + '% of proteins in valid set have at least one NES motifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid[\"NES\"] = NES_bool\n",
    "valid[\"NES positions\"] = NES_valid\n",
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.groupby([\"Global classifier2\", \"NES\"]).count()/valid.groupby(\"Global classifier2\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NES_intersect = []\n",
    "for i in range(len(motifs_loc)):\n",
    "    NES_intersect.append(isintersect(motifs_loc[i],NES_valid[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid[\"NES/Attention Intersect\"] = NES_intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.groupby([\"Global classifier2\", \"NES/Attention Intersect\"]).count()/valid.groupby(\"Global classifier2\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CODE OUTPUT THE INDICES FOR CORRECT AND INCORRECT EXEMPLES.\n",
    "corrects = []\n",
    "falses = []\n",
    "for x in range(len(y_valid)):\n",
    "    if y_valid_indices[x] == y_pred_indices[x]:\n",
    "        corrects.append(x)\n",
    "    else:\n",
    "        falses.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There is ' + str(len(corrects)) + ' correctly classified exemples')\n",
    "print('There is ' + str(len(falses)) + ' incorrectly classified exemples')\n",
    "print('So the accuracy is: ' + str(len(corrects)/len(x_valid)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects_df = valid[valid.index.isin(corrects)]\n",
    "falses_df = valid[valid.index.isin(falses)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "falses_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/3Classes_test.csv\", sep=\"\\t\")\n",
    "y_test = test[\"Global classifier2\"]\n",
    "y_test_indices = cat_to_indices(y_test)\n",
    "y_test_OH = convert_to_one_hot(y_test_indices, C = tot_cat)\n",
    "\n",
    "x_test = test[\"Sequence\"].copy()\n",
    "x_test_indices = seq_to_indices(x_test, aa_to_int, max_len)\n",
    "x_test_pad = sequence.pad_sequences(x_test_indices, maxlen=max_len, value=aa_to_int[\"*\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models_attention/1/weights.32-0.54.hdf5')\n",
    "score = model.evaluate(x_test_pad, y_test_OH)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: CNN LSTM with attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = tot_aa + 1\n",
    "batch_size = 32\n",
    "\n",
    "#LSTM\n",
    "units = 128\n",
    "# Embedding\n",
    "embedding_size = 48\n",
    "# Convolution\n",
    "filters = 20\n",
    "pool_size = 2\n",
    "\n",
    "_input = Input(shape=[max_len], dtype='int32')\n",
    "\n",
    "# get the embedding layer\n",
    "embedded = Embedding(input_dim=max_features,output_dim=embedding_size,\n",
    "        input_length=max_len, name = 'embedding_layer', trainable=True, mask_zero=False)(_input)\n",
    "\n",
    "drop = Dropout(0.2)(embedded)\n",
    "# Convolution layer of different size\n",
    "\n",
    "conv2 = Conv1D(filters, 2, padding='same', activation='relu', \n",
    "              strides=1)(drop)\n",
    "drop2 = SpatialDropout1D(0.2)(conv2)\n",
    "pool2 = MaxPooling1D(pool_size=pool_size)(drop2)\n",
    "\n",
    "conv3 = Conv1D(filters, 3, padding='same', activation='relu', \n",
    "              strides=1)(drop)\n",
    "drop3 = SpatialDropout1D(0.2)(conv3)\n",
    "pool3 = MaxPooling1D(pool_size=pool_size)(drop3)\n",
    "\n",
    "conv5 = Conv1D(filters, 5, padding='same', activation='relu', \n",
    "              strides=1)(drop)\n",
    "drop5 = SpatialDropout1D(0.2)(conv5)\n",
    "pool5 = MaxPooling1D(pool_size=pool_size)(drop5)\n",
    "\n",
    "conv9 = Conv1D(filters, 9, padding='same', activation='relu', \n",
    "              strides=1)(drop)\n",
    "drop9 = SpatialDropout1D(0.2)(conv9)\n",
    "pool9 = MaxPooling1D(pool_size=pool_size)(drop9)\n",
    "\n",
    "conv12 = Conv1D(filters, 12, padding='same', activation='relu', \n",
    "              strides=1)(drop)\n",
    "drop12 = SpatialDropout1D(0.2)(conv12)\n",
    "pool12 = MaxPooling1D(pool_size=pool_size)(drop12)\n",
    "\n",
    "conv16 = Conv1D(filters, 16, padding='same', activation='relu', \n",
    "              strides=1)(drop)\n",
    "drop16 = SpatialDropout1D(0.2)(conv16)\n",
    "pool16 = MaxPooling1D(pool_size=pool_size)(drop16)\n",
    "\n",
    "# Concatenate the filters\n",
    "#concat = concatenate([drop2, drop3, drop5, drop9, drop12], axis=2)\n",
    "concat = concatenate([pool2, pool3, pool5, pool9, pool12, pool16], axis=2)\n",
    "\n",
    "#pool = MaxPooling1D(pool_size=pool_size)(concat)\n",
    "\n",
    "activations = Bidirectional(LSTM(units, return_sequences=True, \n",
    "                                 dropout=0.2, recurrent_dropout=0.2))(concat)\n",
    "\n",
    "# compute importance for each step\n",
    "attention = Dense(1, activation='tanh')(activations)\n",
    "attention = Flatten()(attention)\n",
    "attention = Activation('softmax', name = 'attention_vect')(attention) # attention_vect for visualization\n",
    "attention = RepeatVector(units*2)(attention)\n",
    "attention = Permute([2, 1])(attention)\n",
    "sent_representation = Multiply()([activations, attention])\n",
    "sent_representation = Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(units*2,))(sent_representation)\n",
    "\n",
    "probabilities = Dense(3, activation='softmax')(sent_representation)\n",
    "\n",
    "model = Model(inputs=_input, outputs=probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "model.compile('Nadam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "ckpt = ModelCheckpoint(filepath='models_attention/2/CNN_model_weights', \n",
    "                           verbose=1, save_best_only=True)\n",
    "# Train, train, train\n",
    "history = model.fit(x_train_pad, y_train_OH, \n",
    "                    batch_size=32, epochs=60,\n",
    "                    class_weight = class_weights,\n",
    "          validation_data=[x_valid_pad, y_valid_OH], callbacks=[ckpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='models_attention/2/CNN_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model('models_attention/2/CNN_model_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(x_valid_pad, y_valid_OH, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model2.predict(x_valid_pad)\n",
    "y_pred_indices2 = OH_to_label_indices(y_pred2)\n",
    "y_pred_labels2 = indices_to_cat(y_pred_indices2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mx2 = confusion_matrix(y_valid, y_pred_labels2, labels=cat)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mx2, cmap=plt.cm.gray)\n",
    "fig.colorbar(cax)\n",
    "ax.xaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(MultipleLocator(1))\n",
    "ax.set_xticklabels([''] + cat,  rotation='vertical')\n",
    "ax.set_yticklabels([''] + cat)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Model(inputs=model2.input,\n",
    "              outputs=[model2.output, model2.get_layer('attention_vect').output])\n",
    "outputs2 = model2.predict(x_valid_pad)\n",
    "model_outputs2 = outputs[0]\n",
    "attention_outputs2 = outputs[1]\n",
    "attention_outputs2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize attention values \n",
    "norm_attention2 = []\n",
    "for seq in attention_outputs2:\n",
    "    norm_attention2.append(seq / np.linalg.norm(seq))\n",
    "    \n",
    "attention_distrib2 = np.concatenate( norm_attention2, axis=0 )\n",
    "plt.hist(attention_distrib2, normed=True, bins=50)\n",
    "plt.ylabel('Attention Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So... it has nothing to do with the type of model.. since this is the same I used for 8 compartment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool_size = 2\n",
    "Attention_1500_2 = []\n",
    "A = []\n",
    "for x in norm_attention2:\n",
    "    for i in range(len(x)):\n",
    "        A.append(x[i])\n",
    "        A.append(x[i])\n",
    "    Attention_1500_2.append(np.array(A))\n",
    "    A = []\n",
    "    \n",
    "# Number of highest values to select\n",
    "nb_max = 50\n",
    "max_att_indexes2 = []\n",
    "for seq in Attention_1500_2:\n",
    "    max_att_indexes2.append(np.sort(np.argpartition(seq, -nb_max)[-nb_max:]))\n",
    "max_att_nopad2 = []    \n",
    "for x in range(len(x_valid)):\n",
    "    max_att_nopad2.append(max_att_indexes[x]-(1500-len(x_valid[x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 1\n",
    "\n",
    "def color_charvals(s):\n",
    "    r = 255-int(s.val*255)\n",
    "    color = rgb_to_hex((255,255 , r))\n",
    "    return 'background-color: %s' % color\n",
    "\n",
    "max_ind = max_att_nopad2[X]\n",
    "max_vect = np.zeros(len(x_valid[X]))\n",
    "for val in max_ind:\n",
    "    max_vect[val] = 1\n",
    "# match each aa and attention\n",
    "char_vals = [CharVal(c, v) for c, v in \n",
    "             zip(x_valid[X], max_vect)]\n",
    "\n",
    "char_df = pd.DataFrame(char_vals).transpose()\n",
    "# apply coloring values\n",
    "char_df = char_df.style.applymap(color_charvals)\n",
    "char_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok so with these model the accuracy is better but it didn't pick up the same regions at all (and for both X=3 is wrong)\n",
    "# So maybe convolution or pool is not the best idea because I have not clue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_labels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test CNN model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_pad, y_test_OH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
